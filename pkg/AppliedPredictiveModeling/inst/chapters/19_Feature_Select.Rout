
R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ################################################################################
> ### R code from Applied Predictive Modeling (2013) by Kuhn and Johnson.
> ### Copyright 2013 Kuhn and Johnson
> ### Web Page: http://www.appliedpredictivemodeling.com
> ### Contact: Max Kuhn (mxkuhn@gmail.com) 
> ###
> ### Chapter 19: An Introduction to Feature Selection
> ###
> ### Required packages: AppliedPredictiveModeling, caret, MASS, corrplot,
> ###                    RColorBrewer, randomForest, kernlab, klaR,
> ###                   
> ###
> ### Data used: The Alzheimer disease data from the AppliedPredictiveModeling 
> ###            package
> ###
> ### Notes: 
> ### 1) This code is provided without warranty.
> ###
> ### 2) This code should help the user reproduce the results in the
> ### text. There will be differences between this code and what is is
> ### the computing section. For example, the computing sections show
> ### how the source functions work (e.g. randomForest() or plsr()),
> ### which were not directly used when creating the book. Also, there may be 
> ### syntax differences that occur over time as packages evolve. These files 
> ### will reflect those changes.
> ###
> ### 3) In some cases, the calculations in the book were run in 
> ### parallel. The sub-processes may reset the random number seed.
> ### Your results may slightly vary.
> ###
> ################################################################################
> 
> 
> 
> ################################################################################
> ### Section 19.6 Case Study: Predicting Cognitive Impairment
> 
> 
> library(AppliedPredictiveModeling)
> data(AlzheimerDisease)
> 
> ## The baseline set of predictors
> bl <- c("Genotype", "age", "tau", "p_tau", "Ab_42", "male")
> 
> ## The set of new assays
> newAssays <- colnames(predictors)
> newAssays <- newAssays[!(newAssays %in% c("Class", bl))]
> 
> ## Decompose the genotype factor into binary dummy variables
> 
> predictors$E2 <- predictors$E3 <- predictors$E4 <- 0
> predictors$E2[grepl("2", predictors$Genotype)] <- 1
> predictors$E3[grepl("3", predictors$Genotype)] <- 1
> predictors$E4[grepl("4", predictors$Genotype)] <- 1
> genotype <-  predictors$Genotype
> 
> ## Partition the data
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> set.seed(730)
> split <- createDataPartition(diagnosis, p = .8, list = FALSE)
> 
> adData <- predictors
> adData$Class <- diagnosis
> 
> training <- adData[ split, ]
> testing  <- adData[-split, ]
> 
> predVars <- names(adData)[!(names(adData) %in% c("Class",  "Genotype"))]
> 
> ## This summary function is used to evaluate the models.
> fiveStats <- function(...) c(twoClassSummary(...), defaultSummary(...))
> 
> ## We create the cross-validation files as a list to use with different 
> ## functions
> 
> set.seed(104)
> index <- createMultiFolds(training$Class, times = 5)
> 
> ## The candidate set of the number of predictors to evaluate
> varSeq <- seq(1, length(predVars)-1, by = 2)
> 
> ## We can also use parallel processing to run each resampled RFE
> ## iteration (or resampled model with train()) using different
> ## workers.
> 
> library(doMC)
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
> registerDoMC(15)
> 
> 
> ## The rfe() function in the caret package is used for recursive feature 
> ## elimiation. We setup control functions for this and train() that use
> ## the same cross-validation folds. The 'ctrl' object will be modifed several
> ## times as we try different models
> 
> ctrl <- rfeControl(method = "repeatedcv", repeats = 5,
+                    saveDetails = TRUE,
+                    index = index,
+                    returnResamp = "final")
> 
> fullCtrl <- trainControl(method = "repeatedcv",
+                          repeats = 5,
+                          summaryFunction = fiveStats,
+                          classProbs = TRUE,
+                          index = index)
> 
> ## The correlation matrix of the new data
> predCor <- cor(training[, newAssays])
> 
> library(RColorBrewer)
> cols <- c(rev(brewer.pal(7, "Blues")),
+           brewer.pal(7, "Reds"))
> library(corrplot)
> corrplot(predCor,
+          order = "hclust",
+          tl.pos = "n",addgrid.col = rgb(1,1,1,.01),
+          col = colorRampPalette(cols)(51))
> 
> ## Fit a series of models with the full set of predictors
> set.seed(721)
> rfFull <- train(training[, predVars],
+                 training$Class,
+                 method = "rf",
+                 metric = "ROC",
+                 tuneGrid = data.frame(mtry = floor(sqrt(length(predVars)))),
+                 ntree = 1000,
+                 trControl = fullCtrl)
Loading required package: randomForest
randomForest 4.6-7
Type rfNews() to see new features/changes/bug fixes.
Loading required package: pROC
Loading required package: plyr
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following object is masked from ‘package:stats’:

    cov, smooth, var

Loading required package: class
> rfFull
Random Forest 

267 samples
132 predictors
  2 classes: 'Impaired', 'Control' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 

Summary of sample sizes: 241, 241, 241, 240, 240, 240, ... 

Resampling results

  ROC   Sens  Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD  Accuracy SD
  0.89  0.45  0.985  0.838     0.506  0.0674  0.173    0.0276   0.0508     
  Kappa SD
  0.187   

Tuning parameter 'mtry' was held constant at a value of 11
 
> 
> set.seed(721)
> ldaFull <- train(training[, predVars],
+                  training$Class,
+                  method = "lda",
+                  metric = "ROC",
+                  ## The 'tol' argument helps lda() know when a matrix is 
+                  ## singular. One of the predictors has values very close to 
+                  ## zero, so we raise the vaue to be smaller than the default
+                  ## value of 1.0e-4.
+                  tol = 1.0e-12,
+                  trControl = fullCtrl)
Loading required package: MASS

Attaching package: ‘MASS’

The following object is masked _by_ ‘.GlobalEnv’:

    genotype

> ldaFull
Linear Discriminant Analysis 

267 samples
132 predictors
  2 classes: 'Impaired', 'Control' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 

Summary of sample sizes: 241, 241, 241, 240, 240, 240, ... 

Resampling results

  ROC    Sens   Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD  Accuracy SD
  0.844  0.686  0.829  0.79      0.491  0.0859  0.18     0.0819   0.0659     
  Kappa SD
  0.161   

 
> 
> set.seed(721)
> svmFull <- train(training[, predVars],
+                  training$Class,
+                  method = "svmRadial",
+                  metric = "ROC",
+                  tuneLength = 12,
+                  preProc = c("center", "scale"),
+                  trControl = fullCtrl)
Loading required package: kernlab
> svmFull
Support Vector Machines with Radial Basis Function Kernel 

267 samples
132 predictors
  2 classes: 'Impaired', 'Control' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 5 times) 

Summary of sample sizes: 241, 241, 241, 240, 240, 240, ... 

Resampling results across tuning parameters:

  C     ROC    Sens   Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD
  0.25  0.879  0.725  0.899  0.851     0.625  0.0806  0.157    0.0729 
  0.5   0.879  0.735  0.896  0.852     0.629  0.0806  0.158    0.0769 
  1     0.885  0.706  0.923  0.863     0.645  0.0794  0.157    0.0685 
  2     0.892  0.696  0.933  0.868     0.653  0.0766  0.163    0.0632 
  4     0.886  0.682  0.931  0.863     0.637  0.0762  0.15     0.0565 
  8     0.88   0.644  0.927  0.85      0.599  0.0764  0.145    0.0507 
  16    0.881  0.652  0.923  0.849     0.599  0.076   0.142    0.0516 
  32    0.881  0.652  0.928  0.853     0.607  0.076   0.142    0.0492 
  64    0.881  0.644  0.925  0.848     0.596  0.076   0.14     0.0518 
  128   0.881  0.642  0.921  0.844     0.588  0.076   0.137    0.0556 
  256   0.881  0.647  0.926  0.85      0.599  0.076   0.145    0.0494 
  512   0.881  0.644  0.924  0.847     0.593  0.076   0.145    0.0529 
  Accuracy SD  Kappa SD
  0.0679       0.167   
  0.067        0.163   
  0.0655       0.166   
  0.0573       0.152   
  0.0529       0.143   
  0.0498       0.137   
  0.0502       0.137   
  0.0459       0.127   
  0.0476       0.13    
  0.0491       0.131   
  0.0455       0.127   
  0.0477       0.132   

Tuning parameter 'sigma' was held constant at a value of 0.004505826
ROC was used to select the optimal model using  the largest value.
The final values used for the model were sigma = 0.00451 and C = 2. 
> 
> set.seed(721)
> nbFull <- train(training[, predVars],
+                 training$Class,
+                 method = "nb",
+                 metric = "ROC",
+                 trControl = fullCtrl)
Loading required package: klaR
> nbFull
Naive Bayes 

267 samples
132 predictors
  2 classes: 'Impaired', 'Control' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 

Summary of sample sizes: 241, 241, 241, 240, 240, 240, ... 

Resampling results across tuning parameters:

  usekernel  ROC    Sens   Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD
  FALSE      0.778  0.644  0.78   0.742     0.395  0.107   0.173    0.0931 
  TRUE       0.798  0.594  0.814  0.753     0.397  0.0952  0.174    0.0971 
  Accuracy SD  Kappa SD
  0.0699       0.155   
  0.0792       0.182   

Tuning parameter 'fL' was held constant at a value of 0
ROC was used to select the optimal model using  the largest value.
The final values used for the model were fL = 0 and usekernel = TRUE. 
> 
> lrFull <- train(training[, predVars],
+                 training$Class,
+                 method = "glm",
+                 metric = "ROC",
+                 trControl = fullCtrl)
Warning messages:
1: glm.fit: algorithm did not converge 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
> lrFull
Generalized Linear Model 

267 samples
132 predictors
  2 classes: 'Impaired', 'Control' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 

Summary of sample sizes: 241, 241, 241, 240, 240, 240, ... 

Resampling results

  ROC    Sens  Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD  Accuracy SD
  0.785  0.67  0.778  0.748     0.417  0.101   0.165    0.11     0.0825     
  Kappa SD
  0.172   

 
> 
> set.seed(721)
> knnFull <- train(training[, predVars],
+                  training$Class,
+                  method = "knn",
+                  metric = "ROC",
+                  tuneLength = 20,
+                  preProc = c("center", "scale"),
+                  trControl = fullCtrl)
> knnFull
k-Nearest Neighbors 

267 samples
132 predictors
  2 classes: 'Impaired', 'Control' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 5 times) 

Summary of sample sizes: 241, 241, 241, 240, 240, 240, ... 

Resampling results across tuning parameters:

  k   ROC    Sens    Spec   Accuracy  Kappa   ROC SD  Sens SD  Spec SD
  5   0.753  0.476   0.928  0.804     0.444   0.142   0.184    0.061  
  7   0.76   0.455   0.94   0.807     0.445   0.136   0.157    0.0585 
  9   0.788  0.391   0.963  0.806     0.414   0.107   0.157    0.0374 
  11  0.794  0.369   0.973  0.808     0.408   0.114   0.149    0.0335 
  13  0.79   0.336   0.967  0.794     0.362   0.14    0.15     0.034  
  15  0.817  0.328   0.967  0.792     0.353   0.0753  0.152    0.0411 
  17  0.821  0.298   0.979  0.793     0.338   0.0736  0.157    0.0328 
  19  0.837  0.282   0.986  0.793     0.328   0.0704  0.168    0.0253 
  21  0.847  0.265   0.985  0.788     0.307   0.0704  0.169    0.0261 
  23  0.846  0.248   0.984  0.782     0.292   0.0673  0.121    0.03   
  25  0.843  0.232   0.987  0.78      0.276   0.073   0.126    0.0229 
  27  0.846  0.212   0.989  0.776     0.258   0.0669  0.108    0.0216 
  29  0.849  0.196   0.991  0.773     0.242   0.0687  0.103    0.0201 
  31  0.847  0.182   0.988  0.767     0.221   0.0703  0.0962   0.0268 
  33  0.842  0.171   0.99   0.766     0.209   0.0721  0.107    0.0208 
  35  0.843  0.157   0.991  0.762     0.193   0.0728  0.105    0.0201 
  37  0.842  0.138   0.991  0.757     0.169   0.0705  0.102    0.02   
  39  0.837  0.121   0.995  0.756     0.154   0.0731  0.104    0.0158 
  41  0.831  0.0961  0.995  0.749     0.122   0.0738  0.0932   0.0156 
  43  0.82   0.0739  0.996  0.744     0.0939  0.107   0.0854   0.0142 
  Accuracy SD  Kappa SD
  0.0661       0.195   
  0.0581       0.166   
  0.0541       0.177   
  0.0528       0.174   
  0.0512       0.177   
  0.0517       0.178   
  0.0494       0.183   
  0.05         0.191   
  0.0488       0.186   
  0.0394       0.144   
  0.0386       0.15    
  0.0364       0.135   
  0.0342       0.129   
  0.0326       0.119   
  0.0359       0.139   
  0.0352       0.136   
  0.0328       0.128   
  0.0353       0.137   
  0.0312       0.126   
  0.0288       0.116   

ROC was used to select the optimal model using  the largest value.
The final value used for the model was k = 29. 
> 
> ## Now fit the RFE versions. To do this, the 'functions' argument of the rfe()
> ## object is modified to the approproate functions. For model details about 
> ## these functions and their arguments, see 
> ##
> ##   http://caret.r-forge.r-project.org/featureSelection.html
> ##
> ## for more information.
> 
> 
> 
> 
> ctrl$functions <- rfFuncs
> ctrl$functions$summary <- fiveStats
> set.seed(721)
> rfRFE <- rfe(training[, predVars],
+              training$Class,
+              sizes = varSeq,
+              metric = "ROC",
+              ntree = 1000,
+              rfeControl = ctrl)
> rfRFE

Recursive feature selection

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance over subset size:

 Variables    ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD
         1 0.8067 0.5418 0.8785   0.7867 0.4344 0.09395 0.1856 0.07326
         3 0.8590 0.6518 0.9185   0.8457 0.5929 0.08670 0.1705 0.06688
         5 0.8872 0.6521 0.9468   0.8661 0.6355 0.08310 0.1743 0.06089
         7 0.8870 0.6546 0.9446   0.8652 0.6320 0.11025 0.1929 0.05844
         9 0.8985 0.6711 0.9549   0.8771 0.6618 0.07643 0.1890 0.04689
        11 0.8956 0.6975 0.9611   0.8886 0.6954 0.10711 0.1722 0.04070
        13 0.8996 0.6696 0.9650   0.8839 0.6791 0.10124 0.1659 0.04204
        15 0.8964 0.6782 0.9608   0.8832 0.6771 0.10232 0.1881 0.04215
        17 0.8994 0.6754 0.9619   0.8832 0.6785 0.07797 0.1706 0.04231
        19 0.8965 0.6696 0.9651   0.8840 0.6779 0.07583 0.1823 0.04294
        21 0.8978 0.6450 0.9702   0.8810 0.6645 0.07639 0.1824 0.03578
        23 0.8965 0.6557 0.9651   0.8803 0.6662 0.07511 0.1791 0.04173
        25 0.8958 0.6557 0.9702   0.8841 0.6739 0.07332 0.1786 0.03436
        27 0.8965 0.6400 0.9702   0.8796 0.6599 0.07667 0.1851 0.03578
        29 0.8979 0.6261 0.9733   0.8781 0.6535 0.07581 0.1809 0.04018
        31 0.8974 0.6293 0.9723   0.8781 0.6535 0.07555 0.1869 0.03596
        33 0.8930 0.6171 0.9713   0.8743 0.6413 0.07872 0.1890 0.03988
        35 0.8920 0.6264 0.9702   0.8758 0.6483 0.07962 0.1832 0.04122
        37 0.8937 0.6039 0.9682   0.8682 0.6243 0.07697 0.1925 0.04601
        39 0.8939 0.6014 0.9713   0.8697 0.6277 0.07408 0.1859 0.04277
        41 0.8925 0.5904 0.9712   0.8668 0.6185 0.09554 0.1772 0.04048
        43 0.8908 0.5875 0.9712   0.8660 0.6162 0.09824 0.1721 0.03759
        45 0.8972 0.5764 0.9723   0.8637 0.6053 0.07124 0.1903 0.03746
        47 0.8944 0.5850 0.9713   0.8651 0.6113 0.07291 0.1964 0.04522
        49 0.8958 0.5696 0.9723   0.8616 0.5983 0.07301 0.1975 0.04412
        51 0.8955 0.5554 0.9713   0.8570 0.5839 0.07303 0.1924 0.04265
        53 0.8924 0.5575 0.9702   0.8570 0.5852 0.07102 0.1884 0.04388
        55 0.8935 0.5439 0.9702   0.8532 0.5713 0.07456 0.1904 0.03765
        57 0.8929 0.5196 0.9713   0.8472 0.5517 0.07414 0.1831 0.04032
        59 0.8937 0.5446 0.9743   0.8562 0.5802 0.07611 0.1796 0.04076
        61 0.8925 0.5411 0.9753   0.8561 0.5760 0.07465 0.1976 0.03785
        63 0.8908 0.5450 0.9732   0.8556 0.5774 0.07633 0.1877 0.03788
        65 0.8951 0.5411 0.9743   0.8554 0.5769 0.07304 0.1798 0.03489
        67 0.8965 0.5246 0.9753   0.8517 0.5622 0.07274 0.1834 0.03474
        69 0.8957 0.5196 0.9764   0.8510 0.5592 0.07228 0.1859 0.03642
        71 0.8931 0.5118 0.9754   0.8481 0.5495 0.07485 0.1854 0.03303
        73 0.8907 0.5061 0.9764   0.8473 0.5459 0.07456 0.1851 0.03611
        75 0.8951 0.5061 0.9785   0.8488 0.5498 0.07156 0.1823 0.03111
        77 0.8920 0.5004 0.9722   0.8427 0.5363 0.07632 0.1682 0.03782
        79 0.8923 0.5139 0.9744   0.8481 0.5491 0.07085 0.1950 0.03900
        81 0.8943 0.5061 0.9795   0.8496 0.5508 0.07134 0.1868 0.03097
        83 0.8932 0.4946 0.9795   0.8465 0.5432 0.07049 0.1630 0.03103
        85 0.8927 0.4832 0.9795   0.8435 0.5304 0.07044 0.1722 0.03097
        87 0.8925 0.4914 0.9764   0.8436 0.5335 0.07259 0.1742 0.03483
        89 0.8923 0.4696 0.9774   0.8383 0.5130 0.07230 0.1757 0.03289
        91 0.8916 0.4889 0.9795   0.8450 0.5362 0.07351 0.1702 0.03448
        93 0.8929 0.4693 0.9785   0.8391 0.5158 0.07389 0.1686 0.03439
        95 0.8901 0.4779 0.9826   0.8443 0.5297 0.07283 0.1749 0.02858
        97 0.8918 0.4743 0.9805   0.8420 0.5236 0.07111 0.1713 0.03081
        99 0.8942 0.4800 0.9816   0.8443 0.5296 0.07325 0.1797 0.03055
       101 0.8930 0.4800 0.9805   0.8435 0.5282 0.07164 0.1792 0.02916
       103 0.8924 0.4629 0.9816   0.8397 0.5146 0.06889 0.1634 0.02864
       105 0.8918 0.4575 0.9816   0.8382 0.5089 0.07070 0.1712 0.03055
       107 0.8918 0.4586 0.9837   0.8398 0.5133 0.06979 0.1700 0.02607
       109 0.8942 0.4746 0.9815   0.8428 0.5256 0.06719 0.1710 0.02889
       111 0.8914 0.4632 0.9805   0.8390 0.5117 0.07184 0.1786 0.02916
       113 0.8928 0.4518 0.9826   0.8375 0.5033 0.07029 0.1803 0.02646
       115 0.8935 0.4529 0.9836   0.8383 0.5058 0.06754 0.1793 0.02614
       117 0.8933 0.4464 0.9815   0.8352 0.4978 0.06930 0.1652 0.02687
       119 0.8936 0.4657 0.9857   0.8435 0.5246 0.06720 0.1615 0.02522
       121 0.8891 0.4682 0.9816   0.8412 0.5190 0.07080 0.1736 0.02864
       123 0.8926 0.4418 0.9837   0.8353 0.4965 0.06742 0.1684 0.02796
       125 0.8894 0.4436 0.9847   0.8367 0.4987 0.06941 0.1764 0.02571
       127 0.8936 0.4518 0.9847   0.8390 0.5081 0.06928 0.1708 0.02571
       129 0.8889 0.4468 0.9836   0.8367 0.5003 0.06845 0.1749 0.02614
       131 0.8934 0.4346 0.9847   0.8344 0.4912 0.07038 0.1649 0.02571
       132 0.8877 0.4379 0.9847   0.8352 0.4933 0.07298 0.1726 0.02571
 AccuracySD KappaSD Selected
    0.06711  0.1847         
    0.06934  0.1855         
    0.05988  0.1679         
    0.06634  0.1892         
    0.06103  0.1797         
    0.05451  0.1591         
    0.05200  0.1546        *
    0.05678  0.1700         
    0.05461  0.1627         
    0.05903  0.1749         
    0.05494  0.1723         
    0.05715  0.1724         
    0.05202  0.1642         
    0.05537  0.1717         
    0.05820  0.1790         
    0.05602  0.1765         
    0.05933  0.1855         
    0.05394  0.1683         
    0.05929  0.1837         
    0.06028  0.1882         
    0.05597  0.1763         
    0.05423  0.1704         
    0.05549  0.1842         
    0.06042  0.1929         
    0.05635  0.1855         
    0.05377  0.1800         
    0.05516  0.1801         
    0.05398  0.1891         
    0.05712  0.1893         
    0.04935  0.1670         
    0.05440  0.1919         
    0.05082  0.1779         
    0.05206  0.1765         
    0.05270  0.1842         
    0.05400  0.1842         
    0.05191  0.1838         
    0.05377  0.1906         
    0.05491  0.1918         
    0.05021  0.1690         
    0.05564  0.1955         
    0.05507  0.1950         
    0.04912  0.1670         
    0.04941  0.1777         
    0.05320  0.1855         
    0.04916  0.1798         
    0.05029  0.1790         
    0.04891  0.1745         
    0.04844  0.1775         
    0.05162  0.1851         
    0.05033  0.1850         
    0.05291  0.1895         
    0.04500  0.1684         
    0.05046  0.1808         
    0.05023  0.1786         
    0.04958  0.1780         
    0.05316  0.1929         
    0.05182  0.1923         
    0.05036  0.1882         
    0.04590  0.1745         
    0.04543  0.1677         
    0.05059  0.1828         
    0.04866  0.1791         
    0.05019  0.1903         
    0.05073  0.1864         
    0.04952  0.1862         
    0.04700  0.1795         
    0.04872  0.1865         

The top 5 variables (out of 13):
   Ab_42, tau, p_tau, VEGF, FAS

> 
> ctrl$functions <- ldaFuncs
> ctrl$functions$summary <- fiveStats
> 
> set.seed(721)
> ldaRFE <- rfe(training[, predVars],
+               training$Class,
+               sizes = varSeq,
+               metric = "ROC",
+               tol = 1.0e-12,
+               rfeControl = ctrl)
> ldaRFE

Recursive feature selection

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance over subset size:

 Variables    ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD
         1 0.8483 0.6621 0.8795   0.8201 0.5385 0.08787 0.2009 0.07003
         3 0.8518 0.6243 0.8899   0.8172 0.5208 0.08546 0.2032 0.06947
         5 0.8509 0.6211 0.8979   0.8216 0.5278 0.08457 0.2038 0.06042
         7 0.8517 0.6154 0.9053   0.8255 0.5341 0.08337 0.2241 0.07148
         9 0.8513 0.6264 0.9043   0.8278 0.5424 0.08574 0.2168 0.06818
        11 0.8566 0.6318 0.9176   0.8391 0.5676 0.08869 0.2132 0.06175
        13 0.8818 0.6736 0.9311   0.8603 0.6256 0.08136 0.2104 0.06389
        15 0.8872 0.6779 0.9311   0.8617 0.6298 0.07954 0.1970 0.06091
        17 0.8900 0.6729 0.9215   0.8532 0.6129 0.07704 0.1885 0.07138
        19 0.8975 0.7050 0.9289   0.8676 0.6494 0.07703 0.1940 0.05814
        21 0.9004 0.7050 0.9299   0.8683 0.6503 0.07364 0.1971 0.05628
        23 0.9067 0.7125 0.9289   0.8698 0.6536 0.07214 0.2127 0.05903
        25 0.9109 0.7193 0.9279   0.8708 0.6589 0.06827 0.2026 0.05995
        27 0.9104 0.7350 0.9271   0.8745 0.6720 0.06855 0.1866 0.05694
        29 0.9128 0.7404 0.9322   0.8798 0.6846 0.06828 0.1834 0.05535
        31 0.9128 0.7346 0.9217   0.8706 0.6632 0.06917 0.1819 0.05352
        33 0.9157 0.7429 0.9279   0.8774 0.6790 0.06941 0.1854 0.05217
        35 0.9163 0.7407 0.9217   0.8721 0.6678 0.06746 0.1848 0.05660
        37 0.9131 0.7436 0.9187   0.8706 0.6654 0.06615 0.1861 0.05812
        39 0.9126 0.7461 0.9187   0.8714 0.6679 0.06456 0.1853 0.05899
        41 0.9149 0.7436 0.9155   0.8684 0.6610 0.06764 0.1843 0.06073
        43 0.9131 0.7486 0.9145   0.8691 0.6630 0.06749 0.1872 0.05956
        45 0.9145 0.7539 0.9094   0.8669 0.6606 0.06560 0.1719 0.05729
        47 0.9109 0.7411 0.9011   0.8572 0.6369 0.06528 0.1747 0.05511
        49 0.9119 0.7471 0.9021   0.8595 0.6426 0.06766 0.1817 0.05519
        51 0.9110 0.7471 0.9031   0.8601 0.6430 0.06583 0.1885 0.05267
        53 0.9098 0.7443 0.9043   0.8601 0.6427 0.06406 0.1934 0.06022
        55 0.9082 0.7300 0.9012   0.8541 0.6261 0.06495 0.1950 0.05753
        57 0.9075 0.7350 0.9054   0.8586 0.6367 0.06390 0.1997 0.06148
        59 0.9056 0.7357 0.9115   0.8632 0.6464 0.06710 0.1977 0.05784
        61 0.9082 0.7357 0.9095   0.8617 0.6448 0.06461 0.1885 0.06244
        63 0.9087 0.7300 0.9065   0.8579 0.6364 0.06374 0.1890 0.06966
        65 0.9073 0.7364 0.9036   0.8573 0.6360 0.06500 0.1967 0.06857
        67 0.9043 0.7411 0.9045   0.8595 0.6429 0.06666 0.1847 0.06917
        69 0.8989 0.7414 0.9005   0.8566 0.6363 0.07321 0.1916 0.07001
        71 0.8989 0.7386 0.9003   0.8557 0.6332 0.07140 0.1973 0.07053
        73 0.8980 0.7332 0.9003   0.8542 0.6301 0.07119 0.1840 0.06976
        75 0.8954 0.7354 0.8953   0.8514 0.6275 0.07105 0.1649 0.07786
        77 0.8931 0.7354 0.8899   0.8475 0.6193 0.07323 0.1623 0.07480
        79 0.8911 0.7461 0.8818   0.8445 0.6163 0.07300 0.1430 0.07030
        81 0.8878 0.7489 0.8848   0.8474 0.6235 0.06987 0.1453 0.07379
        83 0.8856 0.7382 0.8733   0.8360 0.5990 0.06906 0.1441 0.08200
        85 0.8836 0.7350 0.8766   0.8376 0.6003 0.07030 0.1485 0.07922
        87 0.8825 0.7296 0.8766   0.8362 0.5961 0.07112 0.1482 0.07726
        89 0.8831 0.7189 0.8726   0.8304 0.5801 0.07049 0.1561 0.07203
        91 0.8813 0.7293 0.8694   0.8310 0.5855 0.07322 0.1527 0.07665
        93 0.8778 0.7236 0.8755   0.8340 0.5893 0.07479 0.1585 0.07555
        95 0.8749 0.7339 0.8745   0.8362 0.5961 0.09342 0.1570 0.07480
        97 0.8827 0.7282 0.8743   0.8345 0.5922 0.07452 0.1570 0.07919
        99 0.8822 0.7371 0.8733   0.8362 0.5959 0.07307 0.1522 0.06643
       101 0.8843 0.7196 0.8765   0.8339 0.5853 0.07526 0.1620 0.06258
       103 0.8808 0.7164 0.8693   0.8278 0.5714 0.07495 0.1717 0.06534
       105 0.8787 0.7318 0.8672   0.8301 0.5805 0.07423 0.1651 0.06133
       107 0.8746 0.7096 0.8682   0.8249 0.5651 0.07805 0.1584 0.06424
       109 0.8679 0.7036 0.8673   0.8227 0.5589 0.09389 0.1616 0.06383
       111 0.8688 0.7064 0.8702   0.8257 0.5653 0.07951 0.1644 0.06510
       113 0.8635 0.7182 0.8652   0.8251 0.5678 0.08714 0.1687 0.06935
       115 0.8623 0.6993 0.8577   0.8145 0.5415 0.09186 0.1710 0.06934
       117 0.8586 0.6968 0.8516   0.8093 0.5307 0.09189 0.1724 0.06903
       119 0.8570 0.6979 0.8518   0.8099 0.5323 0.09064 0.1825 0.07745
       121 0.8581 0.7093 0.8508   0.8121 0.5403 0.08832 0.1768 0.07823
       123 0.8559 0.6957 0.8477   0.8064 0.5241 0.08573 0.1852 0.07355
       125 0.8507 0.6907 0.8404   0.7996 0.5096 0.09223 0.1859 0.07252
       127 0.8439 0.6771 0.8405   0.7959 0.4979 0.08763 0.1894 0.07237
       129 0.8418 0.6739 0.8313   0.7883 0.4827 0.08636 0.1879 0.07310
       131 0.8439 0.6857 0.8294   0.7900 0.4910 0.08593 0.1803 0.08189
       132 0.8439 0.6857 0.8294   0.7900 0.4910 0.08593 0.1803 0.08189
 AccuracySD KappaSD Selected
    0.06212  0.1693         
    0.06092  0.1694         
    0.05878  0.1723         
    0.07356  0.2082         
    0.06843  0.1960         
    0.06755  0.1931         
    0.07173  0.1998         
    0.06132  0.1738         
    0.06709  0.1779         
    0.06469  0.1773         
    0.05814  0.1630         
    0.06293  0.1778         
    0.06107  0.1678         
    0.05941  0.1600         
    0.05484  0.1485         
    0.05414  0.1480         
    0.05343  0.1499         
    0.05565  0.1534        *
    0.05921  0.1614         
    0.05946  0.1604         
    0.05870  0.1577         
    0.05789  0.1585         
    0.05406  0.1445         
    0.05679  0.1521         
    0.05793  0.1556         
    0.05796  0.1586         
    0.05942  0.1618         
    0.06066  0.1687         
    0.06102  0.1704         
    0.05765  0.1624         
    0.05590  0.1549         
    0.05753  0.1524         
    0.06565  0.1722         
    0.06434  0.1671         
    0.06391  0.1670         
    0.06698  0.1765         
    0.06320  0.1639         
    0.06074  0.1485         
    0.06176  0.1516         
    0.05911  0.1417         
    0.06292  0.1510         
    0.06461  0.1510         
    0.05977  0.1408         
    0.06272  0.1476         
    0.06231  0.1524         
    0.06917  0.1646         
    0.06792  0.1640         
    0.06741  0.1630         
    0.07049  0.1658         
    0.06348  0.1552         
    0.06082  0.1547         
    0.06131  0.1588         
    0.05867  0.1505         
    0.05767  0.1460         
    0.06143  0.1582         
    0.05859  0.1501         
    0.06193  0.1546         
    0.06218  0.1573         
    0.06459  0.1642         
    0.07084  0.1784         
    0.06828  0.1704         
    0.07060  0.1793         
    0.06999  0.1790         
    0.06957  0.1782         
    0.07027  0.1782         
    0.06589  0.1611         
    0.06589  0.1611         

The top 5 variables (out of 35):
   Ab_42, tau, p_tau, MMP10, MIF

> 
> ctrl$functions <- nbFuncs
> ctrl$functions$summary <- fiveStats
> set.seed(721)
> nbRFE <- rfe(training[, predVars],
+               training$Class,
+               sizes = varSeq,
+               metric = "ROC",
+               rfeControl = ctrl)
> nbRFE

Recursive feature selection

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance over subset size:

 Variables    ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD
         1 0.8219 0.6286 0.8806   0.8112 0.5133 0.09390 0.1858 0.07246
         3 0.8260 0.6171 0.8537   0.7886 0.4655 0.08952 0.1996 0.08506
         5 0.8176 0.6200 0.8374   0.7774 0.4472 0.08568 0.1868 0.08760
         7 0.8171 0.6107 0.8355   0.7737 0.4368 0.08333 0.1784 0.08128
         9 0.8152 0.6093 0.8274   0.7672 0.4248 0.08766 0.1798 0.08402
        11 0.8197 0.6143 0.8325   0.7723 0.4370 0.08881 0.1644 0.08098
        13 0.8264 0.6532 0.8348   0.7845 0.4720 0.08559 0.1782 0.08413
        15 0.8274 0.6582 0.8325   0.7844 0.4725 0.08184 0.1732 0.07366
        17 0.8318 0.6807 0.8387   0.7950 0.5000 0.08452 0.1690 0.07622
        19 0.8314 0.6671 0.8437   0.7948 0.4955 0.08804 0.1804 0.08144
        21 0.8294 0.6589 0.8426   0.7918 0.4866 0.08704 0.1847 0.08180
        23 0.8275 0.6457 0.8457   0.7904 0.4788 0.09091 0.1952 0.08045
        25 0.8280 0.6436 0.8404   0.7859 0.4697 0.09197 0.1937 0.07888
        27 0.8307 0.6436 0.8456   0.7896 0.4766 0.09182 0.1942 0.07845
        29 0.8291 0.6300 0.8446   0.7852 0.4643 0.09237 0.1952 0.08216
        31 0.8229 0.6182 0.8416   0.7799 0.4508 0.09497 0.1859 0.08083
        33 0.8222 0.6182 0.8386   0.7777 0.4481 0.08826 0.1859 0.08690
        35 0.8185 0.6264 0.8345   0.7769 0.4487 0.09244 0.1806 0.08364
        37 0.8165 0.6243 0.8344   0.7761 0.4454 0.09084 0.1894 0.08191
        39 0.8147 0.6214 0.8324   0.7740 0.4414 0.09174 0.1928 0.08403
        41 0.8113 0.6139 0.8244   0.7659 0.4251 0.09145 0.1896 0.08912
        43 0.8106 0.6111 0.8264   0.7667 0.4251 0.08928 0.1869 0.08561
        45 0.8078 0.6025 0.8212   0.7606 0.4105 0.09236 0.1962 0.08997
        47 0.8031 0.5971 0.8191   0.7576 0.4035 0.09325 0.1960 0.09122
        49 0.8006 0.6021 0.8169   0.7574 0.4048 0.09371 0.1918 0.08948
        51 0.7942 0.5993 0.8096   0.7514 0.3923 0.09367 0.1954 0.08918
        53 0.7942 0.6021 0.8067   0.7500 0.3922 0.09352 0.1929 0.09279
        55 0.7924 0.6025 0.8047   0.7486 0.3897 0.09154 0.1962 0.09277
        57 0.7910 0.5968 0.8037   0.7463 0.3835 0.09229 0.1991 0.09369
        59 0.7905 0.5939 0.8016   0.7441 0.3782 0.09206 0.1984 0.09330
        61 0.7885 0.6054 0.8005   0.7463 0.3872 0.09605 0.1925 0.09374
        63 0.7856 0.6025 0.8035   0.7477 0.3882 0.09639 0.1929 0.09137
        65 0.7853 0.5993 0.7953   0.7409 0.3750 0.09680 0.1954 0.09268
        67 0.7839 0.5996 0.7984   0.7432 0.3796 0.09714 0.1934 0.09261
        69 0.7824 0.5943 0.7994   0.7425 0.3760 0.09728 0.1898 0.09267
        71 0.7787 0.5996 0.7973   0.7425 0.3792 0.10154 0.1845 0.09806
        73 0.7791 0.6025 0.7973   0.7432 0.3809 0.10094 0.1851 0.09763
        75 0.7794 0.5996 0.7942   0.7402 0.3745 0.10232 0.1901 0.09662
        77 0.7792 0.6018 0.7973   0.7432 0.3811 0.10076 0.1810 0.09632
        79 0.7786 0.6100 0.7972   0.7453 0.3875 0.10145 0.1815 0.09363
        81 0.7783 0.6150 0.7973   0.7469 0.3928 0.10362 0.1801 0.09841
        83 0.7785 0.6100 0.7953   0.7440 0.3859 0.10308 0.1833 0.09937
        85 0.7799 0.6043 0.7953   0.7424 0.3807 0.10384 0.1844 0.09601
        87 0.7798 0.6096 0.7984   0.7462 0.3895 0.10427 0.1826 0.09587
        89 0.7796 0.6096 0.7953   0.7439 0.3859 0.10255 0.1826 0.09853
        91 0.7803 0.6043 0.7974   0.7439 0.3838 0.10025 0.1850 0.09901
        93 0.7813 0.6071 0.8025   0.7484 0.3926 0.09988 0.1861 0.09907
        95 0.7819 0.6046 0.8014   0.7469 0.3886 0.09946 0.1900 0.09792
        97 0.7841 0.5989 0.8025   0.7462 0.3852 0.09933 0.1877 0.09702
        99 0.7844 0.5986 0.8025   0.7462 0.3862 0.09856 0.1808 0.09932
       101 0.7856 0.5982 0.8066   0.7492 0.3906 0.09764 0.1842 0.09638
       103 0.7865 0.6007 0.8066   0.7499 0.3934 0.09868 0.1808 0.09638
       105 0.7880 0.6032 0.8097   0.7529 0.3997 0.09868 0.1785 0.09609
       107 0.7881 0.5982 0.8046   0.7476 0.3880 0.09737 0.1876 0.09781
       109 0.7909 0.5954 0.8026   0.7454 0.3825 0.09565 0.1869 0.09620
       111 0.7898 0.5929 0.8036   0.7454 0.3814 0.09557 0.1885 0.09590
       113 0.7914 0.5954 0.8057   0.7476 0.3865 0.09535 0.1864 0.09604
       115 0.7939 0.5982 0.8108   0.7522 0.3961 0.09499 0.1826 0.09499
       117 0.7969 0.5986 0.8118   0.7530 0.3980 0.09534 0.1855 0.09748
       119 0.7948 0.6039 0.8108   0.7537 0.4019 0.09458 0.1827 0.09978
       121 0.7962 0.5986 0.8118   0.7529 0.3990 0.09327 0.1725 0.09878
       123 0.7993 0.5986 0.8108   0.7522 0.3978 0.09368 0.1725 0.09916
       125 0.7999 0.6039 0.8108   0.7537 0.4020 0.09421 0.1733 0.09732
       127 0.7987 0.6014 0.8118   0.7538 0.4014 0.09424 0.1683 0.09737
       129 0.7968 0.6014 0.8108   0.7530 0.4001 0.09664 0.1683 0.09732
       131 0.7980 0.5936 0.8139   0.7530 0.3966 0.09522 0.1742 0.09706
       132 0.7980 0.5936 0.8139   0.7530 0.3966 0.09522 0.1742 0.09706
 AccuracySD KappaSD Selected
    0.05981  0.1591         
    0.07148  0.1822         
    0.06939  0.1721         
    0.06715  0.1668         
    0.06916  0.1679         
    0.06712  0.1629         
    0.07135  0.1725         
    0.07058  0.1762         
    0.06595  0.1587        *
    0.07284  0.1747         
    0.07193  0.1740         
    0.07296  0.1821         
    0.07436  0.1849         
    0.07286  0.1808         
    0.07526  0.1843         
    0.07277  0.1781         
    0.07880  0.1876         
    0.07058  0.1718         
    0.07097  0.1773         
    0.08000  0.1952         
    0.07929  0.1885         
    0.07735  0.1855         
    0.07910  0.1935         
    0.08068  0.1953         
    0.07778  0.1875         
    0.07609  0.1850         
    0.07929  0.1904         
    0.08009  0.1924         
    0.08398  0.2005         
    0.08018  0.1921         
    0.08105  0.1910         
    0.07906  0.1878         
    0.07920  0.1881         
    0.08124  0.1907         
    0.07596  0.1770         
    0.07690  0.1735         
    0.07299  0.1650         
    0.07609  0.1751         
    0.07310  0.1658         
    0.07230  0.1677         
    0.07457  0.1679         
    0.07593  0.1697         
    0.07698  0.1750         
    0.07872  0.1803         
    0.07928  0.1801         
    0.07925  0.1805         
    0.07853  0.1784         
    0.08007  0.1844         
    0.08021  0.1863         
    0.08105  0.1845         
    0.08156  0.1900         
    0.08351  0.1923         
    0.08267  0.1898         
    0.08395  0.1959         
    0.08036  0.1882         
    0.08116  0.1892         
    0.08057  0.1877         
    0.08211  0.1924         
    0.08577  0.2000         
    0.08526  0.1957         
    0.08264  0.1883         
    0.08220  0.1868         
    0.08051  0.1835         
    0.07932  0.1797         
    0.07973  0.1809         
    0.07924  0.1821         
    0.07924  0.1821         

The top 5 variables (out of 17):
   Ab_42, tau, p_tau, MMP10, MIF

> 
> ## Here, the caretFuncs list allows for a model to be tuned at each iteration 
> ## of feature seleciton.
> 
> ctrl$functions <- caretFuncs
> ctrl$functions$summary <- fiveStats
> 
> ## This options tells train() to run it's model tuning
> ## sequentially. Otherwise, there would be parallel processing at two
> ## levels, which is possible but requires W^2 workers. On our machine,
> ## it was more efficient to only run the RFE process in parallel. 
> 
> cvCtrl <- trainControl(method = "cv",
+                        verboseIter = FALSE,
+                        classProbs = TRUE,
+                        allowParallel = FALSE)
> 
> set.seed(721)
> svmRFE <- rfe(training[, predVars],
+               training$Class,
+               sizes = varSeq,
+               rfeControl = ctrl,
+               metric = "ROC",
+               ## Now arguments to train() are used.
+               method = "svmRadial",
+               tuneLength = 12,
+               preProc = c("center", "scale"),
+               trControl = cvCtrl)
> svmRFE

Recursive feature selection

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance over subset size:

 Variables    ROC     Sens   Spec Accuracy     Kappa   ROCSD  SensSD   SpecSD
         1 0.5905 0.000000 0.9958   0.7237 -0.005263 0.09085 0.00000 0.023393
         3 0.6070 0.005357 0.9927   0.7229 -0.002947 0.08997 0.02657 0.018319
         5 0.5768 0.000000 0.9979   0.7252 -0.002887 0.09124 0.00000 0.010418
         7 0.5708 0.002500 0.9989   0.7267  0.001849 0.09078 0.01768 0.007443
         9 0.6014 0.000000 0.9969   0.7245 -0.004216 0.09225 0.00000 0.012209
        11 0.6174 0.002500 0.9917   0.7215 -0.007576 0.08716 0.01768 0.026643
        13 0.6005 0.000000 0.9959   0.7237 -0.005572 0.07947 0.00000 0.013886
        15 0.6089 0.008571 0.9806   0.7148 -0.014105 0.10215 0.03427 0.038157
        17 0.6058 0.013929 0.9826   0.7178 -0.004414 0.10541 0.04227 0.035314
        19 0.6158 0.005714 0.9929   0.7230 -0.002504 0.08359 0.04041 0.022820
        21 0.6314 0.005357 0.9855   0.7177 -0.012255 0.08684 0.02657 0.031549
        23 0.6417 0.000000 0.9897   0.7192 -0.013806 0.10571 0.00000 0.025491
        25 0.6309 0.029286 0.9846   0.7237  0.018380 0.09551 0.07095 0.040661
        27 0.6458 0.023929 0.9919   0.7275  0.019326 0.09345 0.08064 0.021203
        29 0.6488 0.054286 0.9859   0.7314  0.053679 0.09500 0.07627 0.030503
        31 0.6480 0.053929 0.9809   0.7276  0.046498 0.09630 0.07589 0.042807
        33 0.6725 0.062143 0.9601   0.7148  0.029185 0.09998 0.08970 0.059497
        35 0.7088 0.153571 0.9467   0.7298  0.123175 0.10956 0.12796 0.061985
        37 0.7022 0.168929 0.9486   0.7356  0.148679 0.10998 0.10407 0.061053
        39 0.7493 0.326786 0.9245   0.7610  0.291271 0.10438 0.14757 0.065438
        41 0.7538 0.334643 0.9267   0.7650  0.304769 0.09439 0.12942 0.057705
        43 0.7654 0.382500 0.9164   0.7703  0.336838 0.10869 0.16560 0.074757
        45 0.7888 0.448571 0.9062   0.7814  0.388675 0.08715 0.16468 0.077762
        47 0.7972 0.468929 0.9022   0.7839  0.402476 0.08719 0.16326 0.072602
        49 0.8024 0.452857 0.9137   0.7878  0.400875 0.08017 0.17391 0.067174
        51 0.8041 0.464643 0.9136   0.7909  0.415948 0.08680 0.15094 0.067200
        53 0.7975 0.452857 0.9127   0.7870  0.401976 0.08324 0.16405 0.067241
        55 0.7853 0.413214 0.9009   0.7680  0.348189 0.08213 0.14752 0.077139
        57 0.7844 0.438929 0.9135   0.7837  0.390411 0.07783 0.15230 0.070724
        59 0.7870 0.415714 0.8961   0.7644  0.337122 0.07936 0.18739 0.072832
        61 0.7980 0.450714 0.9074   0.7824  0.388683 0.08052 0.17584 0.065940
        63 0.7826 0.421786 0.9082   0.7748  0.361639 0.08169 0.17747 0.063917
        65 0.7864 0.443929 0.9002   0.7751  0.372336 0.08733 0.18343 0.070610
        67 0.7906 0.460000 0.8948   0.7756  0.384999 0.08865 0.14952 0.076753
        69 0.7866 0.434286 0.9051   0.7763  0.371835 0.08833 0.16216 0.064338
        71 0.7906 0.456071 0.9035   0.7810  0.392684 0.09026 0.14814 0.064754
        73 0.7866 0.418929 0.9075   0.7736  0.357854 0.09090 0.17686 0.065723
        75 0.7833 0.429286 0.9002   0.7711  0.361158 0.09241 0.14791 0.064189
        77 0.7918 0.420714 0.9021   0.7706  0.354054 0.09031 0.16442 0.061460
        79 0.7923 0.432500 0.9053   0.7759  0.369002 0.09370 0.16919 0.062353
        81 0.8004 0.471071 0.8983   0.7817  0.397339 0.08313 0.16998 0.064611
        83 0.8019 0.465357 0.8994   0.7808  0.392492 0.09808 0.17318 0.066776
        85 0.8168 0.515357 0.8972   0.7929  0.436919 0.07805 0.16860 0.064093
        87 0.8209 0.498214 0.8983   0.7892  0.423366 0.07254 0.16296 0.061885
        89 0.8242 0.512857 0.8982   0.7930  0.435858 0.07735 0.18215 0.063687
        91 0.8274 0.502500 0.8973   0.7893  0.425311 0.07538 0.17414 0.062171
        93 0.8262 0.497857 0.9063   0.7944  0.432279 0.08008 0.17617 0.054245
        95 0.8206 0.497143 0.9064   0.7945  0.434122 0.07848 0.15594 0.055060
        97 0.8232 0.488929 0.9105   0.7950  0.430581 0.07814 0.17154 0.055436
        99 0.8223 0.500000 0.9075   0.7959  0.437668 0.07680 0.16779 0.062664
       101 0.8218 0.504286 0.9054   0.7958  0.436402 0.07946 0.18323 0.059794
       103 0.8279 0.536429 0.9085   0.8063  0.471852 0.08184 0.18360 0.064848
       105 0.8267 0.543571 0.9014   0.8034  0.470228 0.08120 0.16639 0.065705
       107 0.8251 0.541071 0.9064   0.8063  0.472569 0.07694 0.18172 0.059117
       109 0.8268 0.551429 0.9034   0.8071  0.480250 0.07694 0.16333 0.063430
       111 0.8179 0.527143 0.9002   0.7981  0.452569 0.08383 0.17475 0.065273
       113 0.8156 0.522143 0.9025   0.7984  0.452796 0.08433 0.16804 0.067664
       115 0.8138 0.510357 0.9075   0.7989  0.447754 0.08722 0.16841 0.063067
       117 0.8131 0.528571 0.9013   0.7995  0.455319 0.08265 0.17139 0.063467
       119 0.8188 0.532857 0.9095   0.8064  0.471617 0.08475 0.16431 0.060784
       121 0.8225 0.533571 0.9044   0.8026  0.464322 0.08613 0.17599 0.068058
       123 0.8245 0.538571 0.9022   0.8026  0.466771 0.08876 0.17423 0.071140
       125 0.8815 0.680000 0.9343   0.8647  0.639461 0.08004 0.16685 0.055800
       127 0.8912 0.701786 0.9282   0.8661  0.649271 0.07635 0.16151 0.066473
       129 0.8900 0.701429 0.9302   0.8676  0.652656 0.07869 0.16370 0.066277
       131 0.8914 0.691429 0.9302   0.8646  0.643526 0.07691 0.16485 0.063667
       132 0.8893 0.674286 0.9322   0.8616  0.633022 0.07449 0.15082 0.058051
 AccuracySD KappaSD Selected
    0.02203 0.02882         
    0.01749 0.03100         
    0.01499 0.01428         
    0.01339 0.01307         
    0.01455 0.01686         
    0.02500 0.04221         
    0.01587 0.01909         
    0.02934 0.05591         
    0.02970 0.06116         
    0.01998 0.03986         
    0.02564 0.04107         
    0.02283 0.03372         
    0.03352 0.08812         
    0.02360 0.08907         
    0.02977 0.09988         
    0.03099 0.09088         
    0.04439 0.11421         
    0.04207 0.13477         
    0.04654 0.13361         
    0.05764 0.16761         
    0.05818 0.16646         
    0.06259 0.18393         
    0.06600 0.18597         
    0.06204 0.17159         
    0.05692 0.17232         
    0.06115 0.17055         
    0.06655 0.18785         
    0.06179 0.17173         
    0.06063 0.16750         
    0.06290 0.19192         
    0.05784 0.17611         
    0.06131 0.18280         
    0.06970 0.20398         
    0.06393 0.16434         
    0.06248 0.17773         
    0.06188 0.16790         
    0.06071 0.18004         
    0.05861 0.15959         
    0.06317 0.17973         
    0.06094 0.17690         
    0.06597 0.18691         
    0.06481 0.19130         
    0.05888 0.16835         
    0.05787 0.16558         
    0.07162 0.20140         
    0.06980 0.19570         
    0.06206 0.18188         
    0.05792 0.16732         
    0.05728 0.16662         
    0.06128 0.17683         
    0.06266 0.18665         
    0.06926 0.19777         
    0.06456 0.17840         
    0.06237 0.18096         
    0.06472 0.17957         
    0.06687 0.18908         
    0.06858 0.18914         
    0.06080 0.17232         
    0.06273 0.17956         
    0.06103 0.17401         
    0.06788 0.19012         
    0.06961 0.18870         
    0.06327 0.17249         
    0.05461 0.14531         
    0.06171 0.16233         
    0.05834 0.15316        *
    0.05327 0.14264         

The top 5 variables (out of 131):
   Ab_42, tau, p_tau, MMP10, MIF

> 
> ctrl$functions <- lrFuncs
> ctrl$functions$summary <- fiveStats
> 
> set.seed(721)
> lrRFE <- rfe(training[, predVars],
+                training$Class,
+                sizes = varSeq,
+                metric = "ROC",
+                rfeControl = ctrl)
> lrRFE

Recursive feature selection

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance over subset size:

 Variables    ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD
         1 0.7600 0.3325 0.9313   0.7675 0.2868 0.13224 0.2611 0.06965
         3 0.7787 0.4489 0.9054   0.7800 0.3692 0.13636 0.2786 0.07627
         5 0.8002 0.5332 0.9148   0.8099 0.4651 0.14821 0.2762 0.07436
         7 0.8300 0.6118 0.9067   0.8258 0.5318 0.12810 0.2435 0.07093
         9 0.8497 0.6425 0.9035   0.8317 0.5561 0.10148 0.2136 0.06977
        11 0.8550 0.6589 0.9062   0.8381 0.5792 0.09568 0.1699 0.06843
        13 0.8571 0.6536 0.9053   0.8361 0.5732 0.09524 0.1703 0.06620
        15 0.8543 0.6679 0.9000   0.8361 0.5778 0.10808 0.1706 0.07023
        17 0.8529 0.6729 0.8837   0.8257 0.5564 0.10130 0.1704 0.06520
        19 0.8562 0.6696 0.8866   0.8273 0.5562 0.10051 0.1889 0.06399
        21 0.8515 0.6614 0.8826   0.8220 0.5445 0.10679 0.1867 0.06815
        23 0.8473 0.6811 0.8703   0.8183 0.5447 0.10444 0.1812 0.07585
        25 0.8523 0.6775 0.8682   0.8160 0.5386 0.10208 0.1808 0.07375
        27 0.8448 0.6775 0.8651   0.8138 0.5336 0.10287 0.1871 0.07084
        29 0.8369 0.6914 0.8621   0.8153 0.5406 0.11255 0.1918 0.07864
        31 0.8172 0.6743 0.8518   0.8032 0.5125 0.14429 0.1901 0.07863
        33 0.8239 0.6804 0.8417   0.7974 0.5029 0.10737 0.1839 0.07630
        35 0.7846 0.6850 0.8249   0.7866 0.4862 0.14152 0.1684 0.07715
        37 0.7456 0.6629 0.8212   0.7778 0.4625 0.15954 0.1755 0.07874
        39 0.7291 0.6646 0.8136   0.7732 0.4540 0.15947 0.1853 0.08543
        41 0.7472 0.6707 0.8197   0.7792 0.4659 0.13699 0.1816 0.07805
        43 0.7364 0.6468 0.8153   0.7691 0.4400 0.14810 0.1897 0.08137
        45 0.7636 0.6746 0.8003   0.7657 0.4450 0.10668 0.1683 0.09067
        47 0.7619 0.6904 0.8011   0.7706 0.4602 0.12478 0.1685 0.09794
        49 0.7720 0.6782 0.8156   0.7776 0.4673 0.11553 0.1853 0.09389
        51 0.7819 0.7029 0.8099   0.7800 0.4813 0.11128 0.1693 0.09576
        53 0.7836 0.6939 0.8213   0.7860 0.4916 0.11668 0.1542 0.09829
        55 0.7984 0.7000 0.8159   0.7838 0.4902 0.08453 0.1478 0.10211
        57 0.7741 0.6768 0.8151   0.7765 0.4683 0.12412 0.1706 0.10082
        59 0.7795 0.6657 0.8119   0.7710 0.4551 0.12299 0.1737 0.10371
        61 0.7921 0.6743 0.8189   0.7786 0.4707 0.10119 0.1800 0.09823
        63 0.7885 0.6757 0.8024   0.7674 0.4501 0.10087 0.1745 0.09314
        65 0.7939 0.6786 0.8106   0.7740 0.4637 0.10055 0.1827 0.10282
        67 0.7955 0.6511 0.8046   0.7621 0.4327 0.09315 0.1860 0.09935
        69 0.7980 0.6871 0.8036   0.7712 0.4634 0.10358 0.1645 0.10550
        71 0.7881 0.6864 0.7944   0.7645 0.4525 0.10688 0.1845 0.11695
        73 0.7837 0.6632 0.7944   0.7577 0.4294 0.10418 0.1899 0.10392
        75 0.7841 0.6668 0.7923   0.7570 0.4286 0.10367 0.1970 0.10784
        77 0.7805 0.6682 0.7961   0.7605 0.4370 0.10579 0.1826 0.11082
        79 0.7812 0.6696 0.7985   0.7628 0.4430 0.10462 0.1768 0.11188
        81 0.7837 0.6621 0.7901   0.7545 0.4259 0.09616 0.1793 0.11344
        83 0.7837 0.6486 0.7881   0.7493 0.4109 0.09257 0.1870 0.11317
        85 0.7843 0.6600 0.7858   0.7508 0.4192 0.09711 0.1624 0.11135
        87 0.7869 0.6350 0.7870   0.7447 0.3995 0.08773 0.1785 0.11444
        89 0.7912 0.6679 0.7838   0.7514 0.4236 0.08960 0.1570 0.11414
        91 0.7962 0.6764 0.7851   0.7545 0.4329 0.08569 0.1592 0.11996
        93 0.7918 0.6875 0.7828   0.7559 0.4353 0.08811 0.1699 0.10608
        95 0.7920 0.6689 0.7768   0.7463 0.4130 0.08550 0.1707 0.10948
        97 0.7834 0.6632 0.7791   0.7463 0.4117 0.09253 0.1660 0.11186
        99 0.7832 0.6657 0.7747   0.7438 0.4072 0.08899 0.1731 0.10941
       101 0.7851 0.6679 0.7778   0.7470 0.4150 0.09378 0.1672 0.11201
       103 0.7876 0.6682 0.7758   0.7455 0.4119 0.09109 0.1716 0.11139
       105 0.7872 0.6725 0.7842   0.7529 0.4282 0.09882 0.1589 0.11508
       107 0.7869 0.6775 0.7852   0.7552 0.4330 0.10293 0.1613 0.11178
       109 0.7845 0.6664 0.7841   0.7515 0.4235 0.11155 0.1595 0.11597
       111 0.7831 0.6646 0.7746   0.7440 0.4099 0.10095 0.1708 0.11756
       113 0.7830 0.6646 0.7788   0.7470 0.4131 0.09778 0.1708 0.10983
       115 0.7841 0.6643 0.7778   0.7462 0.4123 0.09882 0.1659 0.11286
       117 0.7827 0.6696 0.7819   0.7507 0.4220 0.10605 0.1594 0.10893
       119 0.7831 0.6675 0.7831   0.7508 0.4195 0.10265 0.1760 0.10406
       121 0.7848 0.6721 0.7779   0.7485 0.4188 0.10165 0.1679 0.11203
       123 0.7839 0.6675 0.7779   0.7471 0.4147 0.10471 0.1686 0.11040
       125 0.7822 0.6696 0.7779   0.7478 0.4175 0.10507 0.1696 0.11471
       127 0.7818 0.6696 0.7779   0.7479 0.4173 0.10490 0.1632 0.10984
       129 0.7825 0.6693 0.7788   0.7485 0.4179 0.10320 0.1659 0.10946
       131 0.7846 0.6696 0.7779   0.7478 0.4170 0.10057 0.1652 0.10989
       132 0.7846 0.6696 0.7779   0.7478 0.4170 0.10057 0.1652 0.10989
 AccuracySD KappaSD Selected
    0.07066  0.2617         
    0.08671  0.2829         
    0.08625  0.2690         
    0.09111  0.2633         
    0.07383  0.2043         
    0.06849  0.1733         
    0.06522  0.1667        *
    0.06775  0.1702         
    0.06406  0.1631         
    0.06541  0.1750         
    0.06900  0.1806         
    0.07172  0.1767         
    0.07361  0.1815         
    0.07640  0.1907         
    0.07496  0.1864         
    0.07783  0.1932         
    0.06920  0.1712         
    0.07455  0.1774         
    0.07537  0.1831         
    0.07624  0.1800         
    0.06610  0.1632         
    0.07209  0.1740         
    0.05611  0.1242         
    0.06826  0.1483         
    0.06754  0.1534         
    0.06433  0.1383         
    0.06896  0.1485         
    0.06929  0.1391         
    0.07736  0.1652         
    0.07985  0.1716         
    0.08330  0.1842         
    0.08009  0.1732         
    0.08553  0.1853         
    0.08245  0.1841         
    0.07897  0.1662         
    0.09083  0.1910         
    0.07839  0.1723         
    0.07590  0.1653         
    0.07576  0.1576         
    0.08382  0.1767         
    0.08406  0.1725         
    0.08361  0.1763         
    0.07799  0.1526         
    0.08361  0.1739         
    0.07821  0.1536         
    0.08338  0.1619         
    0.07202  0.1492         
    0.07270  0.1453         
    0.07160  0.1409         
    0.07181  0.1454         
    0.08167  0.1649         
    0.07988  0.1632         
    0.08179  0.1628         
    0.08254  0.1655         
    0.08433  0.1691         
    0.09071  0.1863         
    0.08187  0.1732         
    0.08055  0.1652         
    0.08032  0.1643         
    0.08034  0.1761         
    0.08198  0.1721         
    0.08217  0.1736         
    0.08674  0.1802         
    0.08394  0.1752         
    0.08337  0.1753         
    0.08250  0.1718         
    0.08250  0.1718         

The top 5 variables (out of 13):
   tau, Cortisol, VEGF, Clusterin_Apo_J, Fetuin_A

> 
> ctrl$functions <- caretFuncs
> ctrl$functions$summary <- fiveStats
> 
> set.seed(721)
> knnRFE <- rfe(training[, predVars],
+               training$Class,
+               sizes = varSeq,
+               metric = "ROC",
+               method = "knn",
+               tuneLength = 20,
+               preProc = c("center", "scale"),
+               trControl = cvCtrl,
+               rfeControl = ctrl)
> knnRFE

Recursive feature selection

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance over subset size:

 Variables    ROC     Sens   Spec Accuracy     Kappa   ROCSD  SensSD  SpecSD
         1 0.6064 0.000000 0.9979   0.7252 -0.002829 0.11620 0.00000 0.01016
         3 0.6105 0.021071 0.9813   0.7191  0.003301 0.10610 0.05503 0.03447
         5 0.6030 0.010714 0.9783   0.7139 -0.014339 0.12140 0.04462 0.04226
         7 0.6138 0.005000 0.9877   0.7193 -0.009955 0.11161 0.02474 0.02842
         9 0.6113 0.035000 0.9701   0.7147  0.006480 0.10063 0.07829 0.04468
        11 0.5891 0.000000 0.9917   0.7208 -0.010703 0.08800 0.00000 0.02841
        13 0.5949 0.000000 1.0000   0.7267  0.000000 0.10663 0.00000 0.00000
        15 0.5941 0.005000 0.9836   0.7162 -0.015025 0.10248 0.02474 0.03487
        17 0.5921 0.000000 0.9907   0.7200 -0.012532 0.09876 0.00000 0.02263
        19 0.6052 0.000000 0.9979   0.7252 -0.002718 0.10539 0.00000 0.01489
        21 0.6080 0.002857 0.9907   0.7207 -0.008502 0.10139 0.02020 0.02488
        23 0.6283 0.005357 0.9857   0.7177 -0.011870 0.10618 0.02657 0.03255
        25 0.6226 0.005357 0.9918   0.7222 -0.003806 0.09542 0.02657 0.02794
        27 0.6105 0.002857 0.9855   0.7169 -0.015451 0.10561 0.02020 0.03329
        29 0.6202 0.005357 0.9908   0.7216 -0.004856 0.12201 0.02657 0.02659
        31 0.5902 0.016786 0.9885   0.7229  0.007459 0.11531 0.04598 0.02856
        33 0.6038 0.026786 0.9848   0.7230  0.015065 0.12858 0.06146 0.03405
        35 0.6339 0.027143 0.9795   0.7191  0.009051 0.13339 0.06209 0.03964
        37 0.6154 0.048929 0.9702   0.7184  0.022169 0.13454 0.10529 0.04676
        39 0.6710 0.104643 0.9598   0.7260  0.082074 0.13048 0.10641 0.04772
        41 0.6559 0.117857 0.9694   0.7365  0.112048 0.12886 0.11595 0.04790
        43 0.6601 0.137857 0.9538   0.7306  0.114381 0.11575 0.13103 0.04776
        45 0.6602 0.112500 0.9487   0.7200  0.076461 0.13013 0.12582 0.05479
        47 0.6943 0.146429 0.9467   0.7275  0.113919 0.12200 0.12367 0.05346
        49 0.6745 0.127500 0.9508   0.7255  0.091337 0.13207 0.16291 0.06245
        51 0.7090 0.197500 0.9425   0.7382  0.164804 0.11652 0.16601 0.05713
        53 0.6945 0.164286 0.9538   0.7373  0.142690 0.12548 0.15692 0.06317
        55 0.6978 0.166786 0.9536   0.7381  0.145468 0.12016 0.15868 0.05358
        57 0.7224 0.225000 0.9301   0.7372  0.182435 0.11323 0.16346 0.07062
        59 0.7086 0.198214 0.9373   0.7353  0.161550 0.12940 0.16359 0.06431
        61 0.7131 0.173571 0.9526   0.7397  0.152089 0.14681 0.15374 0.05339
        63 0.6994 0.201786 0.9508   0.7459  0.185907 0.12576 0.15011 0.05695
        65 0.7067 0.172500 0.9517   0.7388  0.154809 0.12459 0.12248 0.05706
        67 0.7015 0.161429 0.9373   0.7251  0.115826 0.11470 0.15530 0.06475
        69 0.7096 0.178571 0.9415   0.7331  0.143170 0.11379 0.17086 0.07142
        71 0.7136 0.216786 0.9288   0.7342  0.173306 0.10437 0.15212 0.06756
        73 0.6874 0.234286 0.9269   0.7377  0.193418 0.16087 0.14728 0.07524
        75 0.7146 0.177500 0.9496   0.7389  0.159190 0.12630 0.11709 0.05001
        77 0.7189 0.200357 0.9435   0.7403  0.171891 0.14274 0.16054 0.05611
        79 0.7220 0.176786 0.9466   0.7359  0.148615 0.13065 0.15037 0.05573
        81 0.7367 0.227143 0.9597   0.7591  0.227189 0.11942 0.15589 0.04592
        83 0.7392 0.260000 0.9473   0.7597  0.251253 0.12542 0.13251 0.05247
        85 0.7319 0.218214 0.9570   0.7548  0.213702 0.13456 0.15718 0.05740
        87 0.7428 0.259643 0.9516   0.7623  0.252703 0.15221 0.16001 0.05009
        89 0.7439 0.274643 0.9352   0.7545  0.246367 0.11719 0.15914 0.05713
        91 0.7595 0.283214 0.9369   0.7583  0.257821 0.09331 0.16323 0.05074
        93 0.7409 0.256071 0.9350   0.7494  0.228272 0.11549 0.13400 0.05348
        95 0.7524 0.250714 0.9342   0.7471  0.217301 0.09978 0.15667 0.05147
        97 0.7306 0.238214 0.9353   0.7449  0.203307 0.11405 0.15938 0.04691
        99 0.7308 0.280000 0.9268   0.7500  0.241501 0.12963 0.15012 0.05106
       101 0.7265 0.255357 0.9312   0.7465  0.215970 0.10291 0.17091 0.05591
       103 0.7197 0.280714 0.9372   0.7577  0.253722 0.14222 0.17396 0.05224
       105 0.7279 0.234286 0.9436   0.7499  0.211755 0.14193 0.15926 0.05479
       107 0.7456 0.247857 0.9465   0.7554  0.233926 0.11890 0.15194 0.05653
       109 0.7507 0.255000 0.9393   0.7522  0.229079 0.09635 0.16771 0.05939
       111 0.7461 0.255000 0.9590   0.7666  0.259253 0.12612 0.14699 0.04257
       113 0.7518 0.267143 0.9447   0.7592  0.252789 0.09650 0.14879 0.06038
       115 0.7713 0.258214 0.9589   0.7672  0.263819 0.08508 0.14801 0.05072
       117 0.7702 0.243571 0.9498   0.7570  0.234860 0.09519 0.14184 0.05952
       119 0.7605 0.220357 0.9495   0.7499  0.205067 0.08238 0.15292 0.05275
       121 0.7743 0.241786 0.9517   0.7574  0.237198 0.09812 0.12561 0.05411
       123 0.7584 0.280714 0.9467   0.7644  0.268479 0.08869 0.16852 0.05705
       125 0.7942 0.339286 0.9506   0.7832  0.338318 0.07205 0.16489 0.04618
       127 0.7731 0.387857 0.9569   0.8013  0.400311 0.13220 0.16082 0.04310
       129 0.7984 0.422143 0.9548   0.8088  0.432632 0.07905 0.17562 0.05481
       131 0.7769 0.424286 0.9436   0.8014  0.418138 0.13265 0.17293 0.05624
       132 0.7769 0.402143 0.9475   0.7983  0.403517 0.11562 0.15858 0.05861
 AccuracySD KappaSD Selected
    0.01441 0.01401         
    0.03140 0.08531         
    0.03484 0.07018         
    0.02289 0.02972         
    0.03912 0.11306         
    0.02571 0.03597         
    0.01339 0.00000         
    0.02541 0.04511         
    0.02035 0.03032         
    0.01688 0.01922         
    0.02391 0.04407         
    0.02572 0.04782         
    0.02093 0.02935         
    0.02557 0.04149         
    0.02467 0.04702         
    0.02648 0.06738         
    0.02391 0.07722         
    0.03150 0.09220         
    0.03618 0.12457         
    0.03880 0.13217         
    0.04481 0.15396         
    0.05047 0.17032         
    0.05463 0.17769         
    0.03810 0.13242         
    0.04479 0.15554         
    0.04737 0.17116         
    0.04601 0.15784         
    0.04827 0.16931         
    0.05562 0.17556         
    0.05840 0.19088         
    0.04476 0.16073         
    0.05346 0.17446         
    0.04638 0.14586         
    0.04167 0.14837         
    0.06196 0.19803         
    0.05361 0.16956         
    0.06433 0.18473         
    0.04873 0.15096         
    0.05361 0.18296         
    0.04770 0.16618         
    0.05196 0.18409         
    0.05340 0.16931         
    0.05538 0.18451         
    0.05248 0.17640         
    0.05345 0.17649         
    0.05379 0.18031         
    0.04933 0.14716         
    0.05112 0.17577         
    0.04758 0.17363         
    0.05599 0.17706         
    0.04843 0.16940         
    0.05620 0.19190         
    0.05101 0.17896         
    0.05500 0.17980         
    0.05292 0.18030         
    0.04626 0.16770         
    0.04583 0.14661         
    0.05063 0.17167         
    0.05027 0.16002         
    0.04999 0.16962         
    0.04716 0.14377         
    0.05584 0.18904         
    0.04910 0.16983         
    0.04807 0.16637         
    0.06520 0.19926        *
    0.06499 0.19222         
    0.06089 0.17843         

The top 5 variables (out of 129):
   Ab_42, tau, p_tau, MMP10, MIF

> 
> ## Each of these models can be evaluate using the plot() function to see
> ## the profile across subset sizes.
> 
> ## Test set ROC results:
> rfROCfull <- roc(testing$Class,
+                  predict(rfFull, testing[,predVars], type = "prob")[,1])
> rfROCfull

Call:
roc.default(response = testing$Class, predictor = predict(rfFull,     testing[, predVars], type = "prob")[, 1])

Data: predict(rfFull, testing[, predVars], type = "prob")[, 1] in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.9034
> rfROCrfe <- roc(testing$Class,
+                 predict(rfRFE, testing[,predVars])$Impaired)
> rfROCrfe

Call:
roc.default(response = testing$Class, predictor = predict(rfRFE,     testing[, predVars])$Impaired)

Data: predict(rfRFE, testing[, predVars])$Impaired in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8941
> 
> ldaROCfull <- roc(testing$Class,
+                   predict(ldaFull, testing[,predVars], type = "prob")[,1])
> ldaROCfull

Call:
roc.default(response = testing$Class, predictor = predict(ldaFull,     testing[, predVars], type = "prob")[, 1])

Data: predict(ldaFull, testing[, predVars], type = "prob")[, 1] in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8981
> ldaROCrfe <- roc(testing$Class,
+                  predict(ldaRFE, testing[,predVars])$Impaired)
> ldaROCrfe

Call:
roc.default(response = testing$Class, predictor = predict(ldaRFE,     testing[, predVars])$Impaired)

Data: predict(ldaRFE, testing[, predVars])$Impaired in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.9259
> 
> nbROCfull <- roc(testing$Class,
+                   predict(nbFull, testing[,predVars], type = "prob")[,1])
There were 50 or more warnings (use warnings() to see the first 50)
> nbROCfull

Call:
roc.default(response = testing$Class, predictor = predict(nbFull,     testing[, predVars], type = "prob")[, 1])

Data: predict(nbFull, testing[, predVars], type = "prob")[, 1] in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8287
> nbROCrfe <- roc(testing$Class,
+                  predict(nbRFE, testing[,predVars])$Impaired)
Warning message:
In FUN(1:66[[66L]], ...) :
  Numerical 0 probability for all classes with observation 22
> nbROCrfe

Call:
roc.default(response = testing$Class, predictor = predict(nbRFE,     testing[, predVars])$Impaired)

Data: predict(nbRFE, testing[, predVars])$Impaired in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8565
> 
> svmROCfull <- roc(testing$Class,
+                   predict(svmFull, testing[,predVars], type = "prob")[,1])
> svmROCfull

Call:
roc.default(response = testing$Class, predictor = predict(svmFull,     testing[, predVars], type = "prob")[, 1])

Data: predict(svmFull, testing[, predVars], type = "prob")[, 1] in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8727
> svmROCrfe <- roc(testing$Class,
+                  predict(svmRFE, testing[,predVars])$Impaired)
> svmROCrfe

Call:
roc.default(response = testing$Class, predictor = predict(svmRFE,     testing[, predVars])$Impaired)

Data: predict(svmRFE, testing[, predVars])$Impaired in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8681
> 
> lrROCfull <- roc(testing$Class,
+                   predict(lrFull, testing[,predVars], type = "prob")[,1])
> lrROCfull

Call:
roc.default(response = testing$Class, predictor = predict(lrFull,     testing[, predVars], type = "prob")[, 1])

Data: predict(lrFull, testing[, predVars], type = "prob")[, 1] in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8513
> lrROCrfe <- roc(testing$Class,
+                  predict(lrRFE, testing[,predVars])$Impaired)
> lrROCrfe

Call:
roc.default(response = testing$Class, predictor = predict(lrRFE,     testing[, predVars])$Impaired)

Data: predict(lrRFE, testing[, predVars])$Impaired in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.89
> 
> knnROCfull <- roc(testing$Class,
+                   predict(knnFull, testing[,predVars], type = "prob")[,1])
> knnROCfull

Call:
roc.default(response = testing$Class, predictor = predict(knnFull,     testing[, predVars], type = "prob")[, 1])

Data: predict(knnFull, testing[, predVars], type = "prob")[, 1] in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8762
> knnROCrfe <- roc(testing$Class,
+                  predict(knnRFE, testing[,predVars])$Impaired)
> knnROCrfe

Call:
roc.default(response = testing$Class, predictor = predict(knnRFE,     testing[, predVars])$Impaired)

Data: predict(knnRFE, testing[, predVars])$Impaired in 18 controls (testing$Class Impaired) > 48 cases (testing$Class Control).
Area under the curve: 0.8391
> 
> 
> ## For filter methods, the sbf() function (named for Selection By Filter) is
> ## used. It has similar arguments to rfe() to control the model fitting and
> ## filtering methods. 
> 
> ## P-values are created for filtering. 
> 
> ## A set of four LDA models are fit based on two factors: p-value adjustment 
> ## using a Bonferroni adjustment and whether the predictors should be 
> ## pre-screened for high correlations. 
> 
> sbfResamp <- function(x, fun = mean)
+ {
+   x <- unlist(lapply(x$variables, length))
+   fun(x)
+ }
> sbfROC <- function(mod) auc(roc(testing$Class, predict(mod, testing)$Impaired))
> 
> ## This function calculates p-values using either a t-test (when the predictor
> ## has 2+ distinct values) or using Fisher's Exact Test otherwise.
> 
> pScore <- function(x, y)
+   {
+     numX <- length(unique(x))
+     if(numX > 2)
+       {
+        out <- t.test(x ~ y)$p.value
+       } else {
+        out <- fisher.test(factor(x), y)$p.value
+       }
+     out
+   }
> ldaWithPvalues <- ldaSBF
> ldaWithPvalues$score <- pScore
> ldaWithPvalues$summary <- fiveStats
> 
> ## Predictors are retained if their p-value is less than the completely 
> ## subjective cut-off of 0.05.
> 
> ldaWithPvalues$filter <- function (score, x, y)
+ {
+   keepers <- score <= 0.05
+   keepers
+ }
> 
> sbfCtrl <- sbfControl(method = "repeatedcv",
+                       repeats = 5,
+                       verbose = TRUE,
+                       functions = ldaWithPvalues,
+                       index = index)
> 
> rawCorr <- sbf(training[, predVars],
+                training$Class,
+                tol = 1.0e-12,
+                sbfControl = sbfCtrl)
> rawCorr

Selection By Filter

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance:

    ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD AccuracySD KappaSD
 0.9168 0.7439 0.9136    0.867 0.6588 0.06458 0.1778 0.05973     0.0567  0.1512

Using the training set, 47 variables were selected:
   Alpha_1_Antitrypsin, Apolipoprotein_D, B_Lymphocyte_Chemoattractant_BL, Complement_3, Cortisol...

During resampling, the top 5 selected variables (out of a possible 66):
   Ab_42 (100%), age (100%), Cortisol (100%), Creatine_Kinase_MB (100%), Cystatin_C (100%)

On average, 46.1 variables were selected (min = 38, max = 57)
> 
> ldaWithPvalues$filter <- function (score, x, y)
+ {
+   score <- p.adjust(score,  "bonferroni")
+   keepers <- score <= 0.05
+   keepers
+ }
> sbfCtrl <- sbfControl(method = "repeatedcv",
+                       repeats = 5,
+                       verbose = TRUE,
+                       functions = ldaWithPvalues,
+                       index = index)
> 
> adjCorr <- sbf(training[, predVars],
+                training$Class,
+                tol = 1.0e-12,
+                sbfControl = sbfCtrl)
> adjCorr

Selection By Filter

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance:

    ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD AccuracySD KappaSD
 0.8563 0.6443 0.9083   0.8361 0.5663 0.07646  0.201 0.06721    0.06283  0.1778

Using the training set, 17 variables were selected:
   Creatine_Kinase_MB, Eotaxin_3, FAS, GRO_alpha, IGF_BP_2...

During resampling, the top 5 selected variables (out of a possible 23):
   Ab_42 (100%), GRO_alpha (100%), MIF (100%), p_tau (100%), tau (100%)

On average, 13.5 variables were selected (min = 9, max = 19)
> 
> ldaWithPvalues$filter <- function (score, x, y)
+ {
+   keepers <- score <= 0.05
+   corrMat <- cor(x[,keepers])
+   tooHigh <- findCorrelation(corrMat, .75)
+   if(length(tooHigh) > 0) keepers[tooHigh] <- FALSE
+   keepers
+ }
> sbfCtrl <- sbfControl(method = "repeatedcv",
+                       repeats = 5,
+                       verbose = TRUE,
+                       functions = ldaWithPvalues,
+                       index = index)
> 
> rawNoCorr <- sbf(training[, predVars],
+                  training$Class,
+                  tol = 1.0e-12,
+                  sbfControl = sbfCtrl)
> rawNoCorr

Selection By Filter

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance:

   ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD AccuracySD KappaSD
 0.918 0.7357 0.9125   0.8638 0.6508 0.06282 0.1787 0.06498    0.05687  0.1474

Using the training set, 45 variables were selected:
   Alpha_1_Antitrypsin, Apolipoprotein_D, B_Lymphocyte_Chemoattractant_BL, Complement_3, Cortisol...

During resampling, the top 5 selected variables (out of a possible 66):
   Ab_42 (100%), age (100%), E4 (100%), IGF_BP_2 (100%), IL_17E (100%)

On average, 44.3 variables were selected (min = 37, max = 54)
> 
> ldaWithPvalues$filter <- function (score, x, y)
+ {
+   score <- p.adjust(score,  "bonferroni")
+   keepers <- score <= 0.05
+   corrMat <- cor(x[,keepers])
+   tooHigh <- findCorrelation(corrMat, .75)
+   if(length(tooHigh) > 0) keepers[tooHigh] <- FALSE
+   keepers
+ }
> sbfCtrl <- sbfControl(method = "repeatedcv",
+                       repeats = 5,
+                       verbose = TRUE,
+                       functions = ldaWithPvalues,
+                       index = index)
> 
> adjNoCorr <- sbf(training[, predVars],
+                  training$Class,
+                  tol = 1.0e-12,
+                  sbfControl = sbfCtrl)
> adjNoCorr

Selection By Filter

Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 

Resampling performance:

    ROC   Sens   Spec Accuracy  Kappa   ROCSD SensSD  SpecSD AccuracySD KappaSD
 0.8563 0.6443 0.9083   0.8361 0.5663 0.07646  0.201 0.06721    0.06283  0.1778

Using the training set, 17 variables were selected:
   Creatine_Kinase_MB, Eotaxin_3, FAS, GRO_alpha, IGF_BP_2...

During resampling, the top 5 selected variables (out of a possible 23):
   Ab_42 (100%), GRO_alpha (100%), MIF (100%), p_tau (100%), tau (100%)

On average, 13.5 variables were selected (min = 9, max = 19)
> 
> ## Filter methods test set ROC results:
> 
> sbfROC(rawCorr)
Area under the curve: 0.9178
> sbfROC(rawNoCorr)
Area under the curve: 0.9155
> sbfROC(adjCorr)
Area under the curve: 0.9259
> sbfROC(adjNoCorr)
Area under the curve: 0.9259
> 
> ## Get the resampling results for all the models
> 
> rfeResamples <- resamples(list(RF = rfRFE,
+                                "Logistic Reg." = lrRFE,
+                                "SVM" = svmRFE,
+                                "$K$--NN" = knnRFE,
+                                "N. Bayes" = nbRFE,
+                                "LDA" = ldaRFE))
> summary(rfeResamples)

Call:
summary.resamples(object = rfeResamples)

Models: RF, Logistic Reg., SVM, $K$--NN, N. Bayes, LDA 
Number of resamples: 50 

ROC 
                Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF            0.3714  0.8694 0.9229 0.8996  0.9611 1.0000    0
Logistic Reg. 0.6429  0.7984 0.8571 0.8571  0.9370 1.0000    0
SVM           0.7000  0.8421 0.8947 0.8914  0.9611 1.0000    0
$K$--NN       0.6283  0.7332 0.8004 0.7984  0.8709 0.9211    0
N. Bayes      0.6357  0.7759 0.8346 0.8318  0.8797 0.9925    0
LDA           0.7429  0.8716 0.9312 0.9163  0.9783 1.0000    0

Sens 
                Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF            0.2857  0.5714 0.7143 0.6696  0.7500 1.0000    0
Logistic Reg. 0.3750  0.5714 0.6250 0.6536  0.7411 1.0000    0
SVM           0.3750  0.5714 0.7143 0.6914  0.7500 1.0000    0
$K$--NN       0.1250  0.2857 0.4286 0.4221  0.5714 0.7143    0
N. Bayes      0.2857  0.5714 0.7143 0.6807  0.7500 1.0000    0
LDA           0.2500  0.6250 0.7143 0.7407  0.8571 1.0000    0

Spec 
                Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's
RF            0.8500  0.9474 1.0000 0.9650  1.0000    1    0
Logistic Reg. 0.7000  0.8500 0.9000 0.9053  0.9474    1    0
SVM           0.7368  0.8947 0.9474 0.9302  1.0000    1    0
$K$--NN       0.7000  0.9474 0.9500 0.9548  1.0000    1    0
N. Bayes      0.6500  0.8000 0.8421 0.8387  0.8947    1    0
LDA           0.7895  0.8947 0.9000 0.9217  0.9500    1    0

Accuracy 
                Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF            0.7407  0.8519 0.8889 0.8839  0.9252 0.9630    0
Logistic Reg. 0.6667  0.7912 0.8462 0.8361  0.8777 0.9630    0
SVM           0.7692  0.8148 0.8519 0.8646  0.8929 1.0000    0
$K$--NN       0.6071  0.7778 0.8113 0.8088  0.8462 0.9231    0
N. Bayes      0.6538  0.7500 0.7778 0.7950  0.8462 0.9630    0
LDA           0.7407  0.8276 0.8846 0.8721  0.9231 1.0000    0

Kappa 
                 Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF            0.21580  0.5738 0.7027 0.6791  0.7874 0.9078    0
Logistic Reg. 0.23820  0.4717 0.5702 0.5732  0.6676 0.9078    0
SVM           0.35540  0.5408 0.6157 0.6435  0.7450 1.0000    0
$K$--NN       0.05263  0.3307 0.4348 0.4326  0.5737 0.7851    0
N. Bayes      0.21800  0.3999 0.4957 0.5000  0.6370 0.9143    0
LDA           0.28950  0.5519 0.6808 0.6678  0.7851 1.0000    0

> 
> fullResamples <- resamples(list(RF = rfFull,
+                                 "Logistic Reg." = lrFull,
+                                 "SVM" = svmFull,
+                                 "$K$--NN" = knnFull,
+                                 "N. Bayes" = nbFull,
+                                 "LDA" = ldaFull))
> summary(fullResamples)

Call:
summary.resamples(object = fullResamples)

Models: RF, Logistic Reg., SVM, $K$--NN, N. Bayes, LDA 
Number of resamples: 50 

ROC 
                Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF            0.7179  0.8528 0.8980 0.8904  0.9423 1.0000    0
Logistic Reg. 0.5214  0.7240 0.7951 0.7846  0.8612 0.9464    0
SVM           0.7143  0.8441 0.8938 0.8920  0.9611 1.0000    0
$K$--NN       0.7030  0.8047 0.8536 0.8494  0.9011 0.9737    0
N. Bayes      0.5263  0.7237 0.8036 0.7980  0.8690 1.0000    0
LDA           0.5357  0.7864 0.8571 0.8439  0.9059 0.9850    0

Sens 
                Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF            0.0000  0.3080 0.4643 0.4496  0.5714 0.7143    0
Logistic Reg. 0.1429  0.5714 0.7143 0.6696  0.7143 1.0000    0
SVM           0.2857  0.5714 0.7143 0.6964  0.7500 1.0000    0
$K$--NN       0.0000  0.1295 0.1429 0.1957  0.2857 0.4286    0
N. Bayes      0.2500  0.4464 0.5714 0.5936  0.7143 0.8750    0
LDA           0.2500  0.5714 0.7143 0.6857  0.8304 1.0000    0

Spec 
                Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's
RF            0.9000  0.9625 1.0000 0.9847  1.0000    1    0
Logistic Reg. 0.4737  0.7368 0.7895 0.7779  0.8500    1    0
SVM           0.7368  0.9000 0.9474 0.9332  1.0000    1    0
$K$--NN       0.9474  1.0000 1.0000 0.9907  1.0000    1    0
N. Bayes      0.6316  0.7500 0.8000 0.8139  0.8947    1    0
LDA           0.6842  0.7500 0.8421 0.8294  0.8947    1    0

Accuracy 
                Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF            0.7308  0.8148 0.8462 0.8383  0.8846 0.9231    0
Logistic Reg. 0.5185  0.6952 0.7692 0.7478  0.8077 0.8889    0
SVM           0.7407  0.8462 0.8709 0.8683  0.9155 0.9630    0
$K$--NN       0.6923  0.7500 0.7692 0.7731  0.8022 0.8519    0
N. Bayes      0.5714  0.7037 0.7692 0.7530  0.8077 0.8889    0
LDA           0.6667  0.7500 0.7778 0.7900  0.8462 0.9259    0

Kappa 
                  Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RF             0.00000  0.3878 0.5229 0.5057  0.6609 0.7851    0
Logistic Reg. -0.19800  0.3292 0.4336 0.4170  0.5098 0.7417    0
SVM            0.28950  0.5702 0.6554 0.6527  0.7788 0.9065    0
$K$--NN       -0.07216  0.1695 0.1980 0.2417  0.3573 0.5263    0
N. Bayes       0.02326  0.2863 0.4075 0.3966  0.5092 0.7235    0
LDA            0.10330  0.3741 0.4757 0.4910  0.6089 0.8224    0

> 
> filteredResamples <- resamples(list("No Adjustment, Corr Vars" = rawCorr,
+                                     "No Adjustment, No Corr Vars" = rawNoCorr,
+                                     "Bonferroni, Corr Vars" = adjCorr,
+                                     "Bonferroni, No Corr Vars" = adjNoCorr))
> summary(filteredResamples)

Call:
summary.resamples(object = filteredResamples)

Models: No Adjustment, Corr Vars, No Adjustment, No Corr Vars, Bonferroni, Corr Vars, Bonferroni, No Corr Vars 
Number of resamples: 50 

ROC 
                              Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's
No Adjustment, Corr Vars    0.7714  0.8647 0.9281 0.9168  0.9768    1    0
No Adjustment, No Corr Vars 0.7786  0.8816 0.9263 0.9180  0.9759    1    0
Bonferroni, Corr Vars       0.6643  0.8239 0.8531 0.8563  0.8970    1    0
Bonferroni, No Corr Vars    0.6643  0.8239 0.8531 0.8563  0.8970    1    0

Sens 
                              Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's
No Adjustment, Corr Vars    0.2500  0.5848 0.7321 0.7439  0.8571    1    0
No Adjustment, No Corr Vars 0.3750  0.5714 0.7143 0.7357  0.8571    1    0
Bonferroni, Corr Vars       0.2857  0.5000 0.6250 0.6443  0.7500    1    0
Bonferroni, No Corr Vars    0.2857  0.5000 0.6250 0.6443  0.7500    1    0

Spec 
                              Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's
No Adjustment, Corr Vars    0.7895  0.8947    0.9 0.9136    0.95    1    0
No Adjustment, No Corr Vars 0.7500  0.8500    0.9 0.9125    0.95    1    0
Bonferroni, Corr Vars       0.7368  0.8500    0.9 0.9083    0.95    1    0
Bonferroni, No Corr Vars    0.7368  0.8500    0.9 0.9083    0.95    1    0

Accuracy 
                              Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's
No Adjustment, Corr Vars    0.7407  0.8462 0.8571 0.8670  0.8919    1    0
No Adjustment, No Corr Vars 0.7407  0.8226 0.8519 0.8638  0.8889    1    0
Bonferroni, Corr Vars       0.7037  0.7778 0.8462 0.8361  0.8846    1    0
Bonferroni, No Corr Vars    0.7037  0.7778 0.8462 0.8361  0.8846    1    0

Kappa 
                              Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's
No Adjustment, Corr Vars    0.3193  0.5705 0.6609 0.6588  0.7390    1    0
No Adjustment, No Corr Vars 0.3549  0.5702 0.6414 0.6508  0.7381    1    0
Bonferroni, Corr Vars       0.2087  0.4343 0.5766 0.5663  0.6957    1    0
Bonferroni, No Corr Vars    0.2087  0.4343 0.5766 0.5663  0.6957    1    0

> 
> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
 [1] klaR_0.6-7                      kernlab_0.9-16                 
 [3] MASS_7.3-26                     e1071_1.6-1                    
 [5] class_7.3-7                     pROC_1.5.4                     
 [7] plyr_1.8                        randomForest_4.6-7             
 [9] corrplot_0.71                   RColorBrewer_1.0-5             
[11] doMC_1.3.0                      iterators_1.0.6                
[13] foreach_1.4.0                   caret_6.0-22                   
[15] ggplot2_0.9.3.1                 lattice_0.20-15                
[17] AppliedPredictiveModeling_1.1-5

loaded via a namespace (and not attached):
 [1] car_2.0-16       codetools_0.2-8  colorspace_1.2-1 compiler_3.0.1  
 [5] CORElearn_0.9.41 dichromat_2.0-0  digest_0.6.3     grid_3.0.1      
 [9] gtable_0.1.2     labeling_0.1     munsell_0.4      proto_0.3-10    
[13] reshape2_1.2.2   scales_0.2.3     stringr_0.6.2    tools_3.0.1     
> 
> 
> 
> proc.time()
      user     system    elapsed 
257587.585   7078.267  35323.717 

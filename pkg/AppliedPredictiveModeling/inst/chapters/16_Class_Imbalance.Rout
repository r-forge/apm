
R version 3.0.0 RC (2013-03-27 r62426) -- "Masked Marvel"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ################################################################################
> ### R code from Applied Predictive Modeling (2013) by Kuhn and Johnson.
> ### Copyright 2013 Kuhn and Johnson
> ### Web Page: http://www.appliedpredictivemodeling.com
> ### Contact: Max Kuhn (mxkuhn@gmail.com) 
> ###
> ### Chapter 16: Remedies for Severe Class Imbalance
> ###
> ### Required packages: AppliedPredictiveModeling, caret, C50, earth, DMwR, 
> ###                    DVD, kernlab,  mda, pROC, randomForest, rpart
> ###
> ### Data used: The insurance data from the DWD package. 
> ###
> ### Notes: 
> ### 1) This code is provided without warranty.
> ###
> ### 2) This code should help the user reproduce the results in the
> ### text. There will be differences between this code and what is is
> ### the computing section. For example, the computing sections show
> ### how the source functions work (e.g. randomForest() or plsr()),
> ### which were not directly used when creating the book. Also, there may be 
> ### syntax differences that occur over time as packages evolve. These files 
> ### will reflect those changes.
> ###
> ### 3) In some cases, the calculations in the book were run in 
> ### parallel. The sub-processes may reset the random number seed.
> ### Your results may slightly vary.
> ###
> ################################################################################
> 
> ################################################################################
> ### Section 16.1 Case Study: Predicting Caravan Policy Ownership
> 
> library(DWD)
Loading required package: Matrix
Loading required package: lattice
> data(ticdata)
> 
> ### Some of the predictor names and levels have characters that would results in
> ### illegal variable names. We convert then to more generic names and treat the
> ### ordered factors as nominal (i.e. unordered) factors. 
> 
> isOrdered <- unlist(lapply(ticdata, function(x) any(class(x) == "ordered")))
> 
> recodeLevels <- function(x)
+   {
+     x <- gsub("f ", "", as.character(x))
+     x <- gsub(" - ", "_to_", x)
+     x <- gsub("-", "_to_", x)
+     x <- gsub("%", "", x)
+     x <- gsub("?", "Unk", x, fixed = TRUE)
+     x <- gsub("[,'\\(\\)]", "", x)
+     x <- gsub(" ", "_", x)
+     factor(paste("_", x, sep = ""))
+   }
> 
> convertCols <- c("STYPE", "MGEMLEEF", "MOSHOOFD",
+                  names(isOrdered)[isOrdered])
> 
> for(i in convertCols) ticdata[,i] <- factor(gsub(" ", "0",format(as.numeric(ticdata[,i]))))
> 
> ticdata$CARAVAN <- factor(as.character(ticdata$CARAVAN),
+                           levels = rev(levels(ticdata$CARAVAN)))
> 
> ### Split the data into three sets: training, test and evaluation. 
> library(caret)
Loading required package: cluster
Loading required package: foreach
Loading required package: plyr
Loading required package: reshape2
> 
> set.seed(156)
> 
> split1 <- createDataPartition(ticdata$CARAVAN, p = .7)[[1]]
> 
> other     <- ticdata[-split1,]
> training  <- ticdata[ split1,]
> 
> set.seed(934)
> 
> split2 <- createDataPartition(other$CARAVAN, p = 1/3)[[1]]
> 
> evaluation  <- other[ split2,]
> testing     <- other[-split2,]
> 
> predictors <- names(training)[names(training) != "CARAVAN"]
> 
> testResults <- data.frame(CARAVAN = testing$CARAVAN)
> evalResults <- data.frame(CARAVAN = evaluation$CARAVAN)
> 
> trainingInd <- data.frame(model.matrix(CARAVAN ~ ., data = training))[,-1]
> evaluationInd <- data.frame(model.matrix(CARAVAN ~ ., data = evaluation))[,-1]
> testingInd <- data.frame(model.matrix(CARAVAN ~ ., data = testing))[,-1]
> 
> trainingInd$CARAVAN <- training$CARAVAN
> evaluationInd$CARAVAN <- evaluation$CARAVAN
> testingInd$CARAVAN <- testing$CARAVAN
> 
> isNZV <- nearZeroVar(trainingInd)
> noNZVSet <- names(trainingInd)[-isNZV]
> 
> testResults <- data.frame(CARAVAN = testing$CARAVAN)
> evalResults <- data.frame(CARAVAN = evaluation$CARAVAN)
> 
> ################################################################################
> ### Section 16.2 The Effect of Class Imbalance
> 
> ### These functions are used to measure performance
> 
> fiveStats <- function(...) c(twoClassSummary(...), defaultSummary(...))
> fourStats <- function (data, lev = levels(data$obs), model = NULL)
+ {
+ 
+   accKapp <- postResample(data[, "pred"], data[, "obs"])
+   out <- c(accKapp,
+            sensitivity(data[, "pred"], data[, "obs"], lev[1]),
+            specificity(data[, "pred"], data[, "obs"], lev[2]))
+   names(out)[3:4] <- c("Sens", "Spec")
+   out
+ }
> 
> ctrl <- trainControl(method = "cv",
+                      classProbs = TRUE,
+                      summaryFunction = fiveStats)
> 
> ctrlNoProb <- ctrl
> ctrlNoProb$summaryFunction <- fourStats
> ctrlNoProb$classProbs <- FALSE
> 
> ### Optional: parallel processing can be used via the 'do' packages,
> ### such as doMC, doMPI etc. We used doMC (not on Windows) to speed
> ### up the computations.
> 
> ### WARNING: Be aware of how much memory is needed to parallel
> ### process. It can very quickly overwhelm the available hardware. The
> ### estimate of the median memory usage (VSIZE = total memory size) 
> ### was 2800M/core. 
> 
> library(doMC)
Loading required package: iterators
Loading required package: parallel
> registerDoMC(15)
> 
> set.seed(1410)
> rfFit <- train(CARAVAN ~ ., data = trainingInd,
+                method = "rf",
+                trControl = ctrl,
+                ntree = 1500,
+                tuneLength = 5,
+                metric = "ROC")
randomForest 4.6-7
Type rfNews() to see new features/changes/bug fixes.
Loading required package: pROC
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following object is masked from ‘package:stats’:

    cov, smooth, var

Loading required package: class
> rfFit
6877 samples
 503 predictors
   2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 6190, 6190, 6188, 6189, 6189, 6190, ... 

Resampling results across tuning parameters:

  mtry  ROC    Sens    Spec   Accuracy  Kappa      ROC SD  Sens SD  Spec SD
  2     0.63   0       1      0.94      0          0.0304  0        0      
  7     0.671  0       1      0.94      -0.000285  0.0387  0        0.00049
  31    0.69   0.0171  0.994  0.935     0.0186     0.0373  0.0165   0.0033 
  126   0.695  0.0317  0.985  0.928     0.0273     0.0367  0.0201   0.00491
  502   0.689  0.0463  0.979  0.923     0.0363     0.0423  0.0243   0.00415
  Accuracy SD  Kappa SD
  0.000422     0       
  0.000602     0.000901
  0.00382      0.031   
  0.00565      0.0369  
  0.00496      0.0381  

ROC was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 126. 
> 
> evalResults$RF <- predict(rfFit, evaluationInd, type = "prob")[,1]
> testResults$RF <- predict(rfFit, testingInd, type = "prob")[,1]
> rfROC <- roc(evalResults$CARAVAN, evalResults$RF,
+              levels = rev(levels(evalResults$CARAVAN)))
> rfROC

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$RF,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$RF in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7569
> 
> rfEvalCM <- confusionMatrix(predict(rfFit, evaluationInd), evalResults$CARAVAN)
> rfEvalCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance           4           9
  noinsurance        55         915
                                          
               Accuracy : 0.9349          
                 95% CI : (0.9176, 0.9495)
    No Information Rate : 0.94            
    P-Value [Acc > NIR] : 0.7727          
                                          
                  Kappa : 0.0914          
 Mcnemar's Test P-Value : 1.855e-08       
                                          
            Sensitivity : 0.067797        
            Specificity : 0.990260        
         Pos Pred Value : 0.307692        
         Neg Pred Value : 0.943299        
             Prevalence : 0.060020        
         Detection Rate : 0.004069        
   Detection Prevalence : 0.013225        
                                          
       'Positive' Class : insurance       
                                          
> 
> set.seed(1410)
> lrFit <- train(CARAVAN ~ .,
+                data = trainingInd[, noNZVSet],
+                method = "glm",
+                trControl = ctrl,
+                metric = "ROC")
> lrFit
6877 samples
 203 predictors
   2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 6190, 6190, 6188, 6189, 6189, 6190, ... 

Resampling results

  ROC    Sens    Spec   Accuracy  Kappa   ROC SD  Sens SD  Spec SD  Accuracy SD
  0.702  0.0121  0.998  0.939     0.0179  0.0488  0.0128   0.0032   0.00323    
  Kappa SD
  0.0249  

 
> 
> evalResults$LogReg <- predict(lrFit, evaluationInd[, noNZVSet], type = "prob")[,1]
Warning messages:
1: In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
2: In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
> testResults$LogReg <- predict(lrFit, testingInd[, noNZVSet], type = "prob")[,1]
Warning messages:
1: In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
2: In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
> lrROC <- roc(evalResults$CARAVAN, evalResults$LogReg,
+              levels = rev(levels(evalResults$CARAVAN)))
> lrROC

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$LogReg,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$LogReg in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7267
> 
> lrEvalCM <- confusionMatrix(predict(lrFit, evaluationInd), evalResults$CARAVAN)
Warning message:
In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
> lrEvalCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance           1           2
  noinsurance        58         922
                                          
               Accuracy : 0.939           
                 95% CI : (0.9221, 0.9531)
    No Information Rate : 0.94            
    P-Value [Acc > NIR] : 0.5872          
                                          
                  Kappa : 0.0266          
 Mcnemar's Test P-Value : 1.243e-12       
                                          
            Sensitivity : 0.016949        
            Specificity : 0.997835        
         Pos Pred Value : 0.333333        
         Neg Pred Value : 0.940816        
             Prevalence : 0.060020        
         Detection Rate : 0.001017        
   Detection Prevalence : 0.003052        
                                          
       'Positive' Class : insurance       
                                          
> 
> set.seed(1401)
> fdaFit <- train(CARAVAN ~ ., data = training,
+                 method = "fda",
+                 tuneGrid = data.frame(.degree = 1, .nprune = 1:25),
+                 metric = "ROC",
+                 trControl = ctrl)
Loading required package: leaps
Loading required package: leaps
Loading required package: plotmo
Loading required package: plotmo
Loading required package: leaps
Loading required package: leaps
Loading required package: leaps
Loading required package: leaps
Loading required package: plotrix
Loading required package: plotrix
Loading required package: leaps
Loading required package: plotmo
Loading required package: plotmo
Loading required package: plotmo
Loading required package: leaps
Loading required package: leaps
Loading required package: plotmo
Loading required package: leaps
Loading required package: leaps
Loading required package: leaps
Loading required package: plotrix
Loading required package: leaps
Loading required package: plotrix
Loading required package: plotrix
Loading required package: plotmo
Loading required package: plotmo
Loading required package: plotmo
Loading required package: plotmo
Loading required package: plotrix
Loading required package: plotmo
Loading required package: leaps
Loading required package: plotmo
Loading required package: plotrix
Loading required package: plotmo
Loading required package: plotrix
Loading required package: plotrix
Loading required package: plotrix
Loading required package: plotrix
Loading required package: plotrix
Loading required package: plotrix
Loading required package: plotmo
Loading required package: leaps
Loading required package: plotrix
Loading required package: plotmo
Loading required package: plotrix
Loading required package: leaps
Loading required package: plotmo
Loading required package: plotrix
> fdaFit
6877 samples
  85 predictors
   2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 6189, 6190, 6190, 6189, 6189, 6189, ... 

Resampling results across tuning parameters:

  nprune  ROC    Sens    Spec   Accuracy  Kappa    ROC SD  Sens SD  Spec SD
  1       0.5    0       1      0.94      0        0       0        0      
  2       0.664  0       1      0.94      0        0.0291  0        0      
  3       0.691  0       0.999  0.94      -0.0011  0.0272  0        0.00149
  4       0.705  0.0146  0.997  0.938     0.0201   0.0333  0.0171   0.00231
  5       0.704  0.0146  0.997  0.938     0.0206   0.0303  0.0171   0.00251
  6       0.723  0.0244  0.997  0.938     0.0358   0.0325  0.0304   0.00204
  7       0.724  0.0268  0.995  0.937     0.035    0.0323  0.0372   0.00292
  8       0.724  0.0268  0.995  0.937     0.0347   0.0316  0.0372   0.00311
  9       0.728  0.0293  0.995  0.937     0.0383   0.0315  0.0378   0.0032 
  10      0.727  0.0317  0.994  0.936     0.0393   0.0339  0.0382   0.00482
  11      0.73   0.0366  0.993  0.936     0.0475   0.0351  0.0368   0.00484
  12      0.73   0.0415  0.992  0.936     0.0531   0.0325  0.0364   0.00452
  13      0.734  0.0488  0.993  0.936     0.0651   0.0385  0.0398   0.00411
  14      0.73   0.0488  0.992  0.935     0.0626   0.034   0.0415   0.004  
  15      0.732  0.0463  0.992  0.935     0.0599   0.0327  0.0422   0.00307
  16      0.728  0.0537  0.991  0.935     0.0707   0.0356  0.0427   0.00311
  17      0.732  0.0512  0.991  0.935     0.0647   0.0353  0.0437   0.00409
  18      0.731  0.0512  0.991  0.935     0.0648   0.0362  0.0466   0.00398
  19      0.729  0.0488  0.991  0.934     0.0597   0.0369  0.0488   0.00425
  20      0.727  0.0488  0.991  0.934     0.0599   0.0364  0.0488   0.00399
  21      0.727  0.0488  0.991  0.934     0.0599   0.0364  0.0488   0.00399
  22      0.727  0.0488  0.991  0.934     0.0599   0.0364  0.0488   0.00399
  23      0.727  0.0488  0.991  0.934     0.0599   0.0364  0.0488   0.00399
  24      0.727  0.0488  0.991  0.934     0.0599   0.0364  0.0488   0.00399
  25      0.727  0.0488  0.991  0.934     0.0599   0.0364  0.0488   0.00399
  Accuracy SD  Kappa SD
  0.000452     0       
  0.000452     0       
  0.0014       0.00265 
  0.00222      0.0286  
  0.00209      0.0281  
  0.00268      0.0509  
  0.0023       0.0541  
  0.0026       0.0544  
  0.0026       0.0553  
  0.00315      0.0509  
  0.00346      0.0495  
  0.00292      0.0481  
  0.00295      0.0557  
  0.00267      0.0575  
  0.00267      0.0614  
  0.00337      0.0637  
  0.00339      0.0624  
  0.00327      0.0652  
  0.00331      0.0679  
  0.00324      0.0685  
  0.00324      0.0685  
  0.00324      0.0685  
  0.00324      0.0685  
  0.00324      0.0685  
  0.00324      0.0685  

Tuning parameter 'degree' was held constant at a value of 1
ROC was used to select the optimal model using  the largest value.
The final values used for the model were nprune = 13 and degree = 1. 
> 
> evalResults$FDA <- predict(fdaFit, evaluation[, predictors], type = "prob")[,1]
> testResults$FDA <- predict(fdaFit, testing[, predictors], type = "prob")[,1]
> fdaROC <- roc(evalResults$CARAVAN, evalResults$FDA,
+               levels = rev(levels(evalResults$CARAVAN)))
> fdaROC

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$FDA,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$FDA in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.754
> 
> fdaEvalCM <- confusionMatrix(predict(fdaFit, evaluation[, predictors]), evalResults$CARAVAN)
> fdaEvalCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance           1           3
  noinsurance        58         921
                                         
               Accuracy : 0.9379         
                 95% CI : (0.921, 0.9522)
    No Information Rate : 0.94           
    P-Value [Acc > NIR] : 0.638          
                                         
                  Kappa : 0.0243         
 Mcnemar's Test P-Value : 4.712e-12      
                                         
            Sensitivity : 0.016949       
            Specificity : 0.996753       
         Pos Pred Value : 0.250000       
         Neg Pred Value : 0.940756       
             Prevalence : 0.060020       
         Detection Rate : 0.001017       
   Detection Prevalence : 0.004069       
                                         
       'Positive' Class : insurance      
                                         
> 
> 
> labs <- c(RF = "Random Forest", LogReg = "Logistic Regression",
+           FDA = "FDA (MARS)")
> lift1 <- lift(CARAVAN ~ RF + LogReg + FDA, data = evalResults,
+               labels = labs)
> 
> plotTheme <- caretTheme()
> 
> plot(fdaROC, type = "S", col = plotTheme$superpose.line$col[3], legacy.axes = TRUE)

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$FDA,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$FDA in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.754
> plot(rfROC, type = "S", col = plotTheme$superpose.line$col[1], add = TRUE, legacy.axes = TRUE)

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$RF,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$RF in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7569
> plot(lrROC, type = "S", col = plotTheme$superpose.line$col[2], add = TRUE, legacy.axes = TRUE)

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$LogReg,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$LogReg in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7267
> legend(.7, .25,
+        c("Random Forest", "Logistic Regression", "FDA (MARS)"),
+        cex = .85,
+        col = plotTheme$superpose.line$col[1:3],
+        lwd = rep(2, 3),
+        lty = rep(1, 3))
> 
> xyplot(lift1,
+        ylab = "%Events Found",
+        xlab =  "%Customers Evaluated",
+        lwd = 2,
+        type = "l")
> 
> 
> ################################################################################
> ### Section 16.4 Alternate Cutoffs
> 
> rfThresh <- coords(rfROC, x = "best", ret="threshold",
+                    best.method="closest.topleft")
> rfThreshY <- coords(rfROC, x = "best", ret="threshold",
+                     best.method="youden")
> 
> cutText <- ifelse(rfThresh == rfThreshY,
+                   "is the same as",
+                   "is similar to")
> 
> evalResults$rfAlt <- factor(ifelse(evalResults$RF > rfThresh,
+                                    "insurance", "noinsurance"),
+                             levels = levels(evalResults$CARAVAN))
> testResults$rfAlt <- factor(ifelse(testResults$RF > rfThresh,
+                                    "insurance", "noinsurance"),
+                             levels = levels(testResults$CARAVAN))
> rfAltEvalCM <- confusionMatrix(evalResults$rfAlt, evalResults$CARAVAN)
> rfAltEvalCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          38         223
  noinsurance        21         701
                                          
               Accuracy : 0.7518          
                 95% CI : (0.7235, 0.7785)
    No Information Rate : 0.94            
    P-Value [Acc > NIR] : 1               
                                          
                  Kappa : 0.1547          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.64407         
            Specificity : 0.75866         
         Pos Pred Value : 0.14559         
         Neg Pred Value : 0.97091         
             Prevalence : 0.06002         
         Detection Rate : 0.03866         
   Detection Prevalence : 0.26551         
                                          
       'Positive' Class : insurance       
                                          
> 
> rfAltTestCM <- confusionMatrix(testResults$rfAlt, testResults$CARAVAN)
> rfAltTestCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          71         441
  noinsurance        45        1405
                                          
               Accuracy : 0.7523          
                 95% CI : (0.7326, 0.7713)
    No Information Rate : 0.9409          
    P-Value [Acc > NIR] : 1               
                                          
                  Kappa : 0.1435          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.61207         
            Specificity : 0.76111         
         Pos Pred Value : 0.13867         
         Neg Pred Value : 0.96897         
             Prevalence : 0.05912         
         Detection Rate : 0.03619         
   Detection Prevalence : 0.26096         
                                          
       'Positive' Class : insurance       
                                          
> 
> rfTestCM <- confusionMatrix(predict(rfFit, testingInd), testResults$CARAVAN)
> 
> 
> plot(rfROC, print.thres = c(.5, .3, .10, rfThresh), type = "S",
+      print.thres.pattern = "%.3f (Spec = %.2f, Sens = %.2f)",
+      print.thres.cex = .8, legacy.axes = TRUE)

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$RF,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$RF in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7569
> 
> ################################################################################
> ### Section 16.5 Adjusting Prior Probabilities
> 
> priors <- table(ticdata$CARAVAN)/nrow(ticdata)*100
> fdaPriors <- fdaFit
> fdaPriors$finalModel$prior <- c(insurance = .6, noinsurance =  .4)
> fdaPriorPred <- predict(fdaPriors, evaluation[,predictors])
> evalResults$FDAprior <-  predict(fdaPriors, evaluation[,predictors], type = "prob")[,1]
> testResults$FDAprior <-  predict(fdaPriors, testing[,predictors], type = "prob")[,1]
> fdaPriorCM <- confusionMatrix(fdaPriorPred, evaluation$CARAVAN)
> fdaPriorCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          42         306
  noinsurance        17         618
                                          
               Accuracy : 0.6714          
                 95% CI : (0.6411, 0.7007)
    No Information Rate : 0.94            
    P-Value [Acc > NIR] : 1               
                                          
                  Kappa : 0.1156          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.71186         
            Specificity : 0.66883         
         Pos Pred Value : 0.12069         
         Neg Pred Value : 0.97323         
             Prevalence : 0.06002         
         Detection Rate : 0.04273         
   Detection Prevalence : 0.35402         
                                          
       'Positive' Class : insurance       
                                          
> 
> fdaPriorROC <- roc(testResults$CARAVAN, testResults$FDAprior,
+                    levels = rev(levels(testResults$CARAVAN)))
> fdaPriorROC

Call:
roc.default(response = testResults$CARAVAN, predictor = testResults$FDAprior,     levels = rev(levels(testResults$CARAVAN)))

Data: testResults$FDAprior in 1846 controls (testResults$CARAVAN noinsurance) < 116 cases (testResults$CARAVAN insurance).
Area under the curve: 0.7469
> 
> ################################################################################
> ### Section 16.7 Sampling Methods
> 
> set.seed(1237)
> downSampled <- downSample(trainingInd[, -ncol(trainingInd)], training$CARAVAN)
> 
> set.seed(1237)
> upSampled <- upSample(trainingInd[, -ncol(trainingInd)], training$CARAVAN)
> 
> library(DMwR)
Loading required package: xts
Loading required package: zoo

Attaching package: ‘zoo’

The following object is masked from ‘package:base’:

    as.Date, as.Date.numeric

Loading required package: quantmod
Loading required package: Defaults
Loading required package: TTR
Version 0.4-0 included new data defaults. See ?getSymbols.
Loading required package: ROCR
Loading required package: gplots
Loading required package: gtools

Attaching package: ‘gtools’

The following object is masked from ‘package:e1071’:

    permutations

Loading required package: gdata
'.path.package' is deprecated.
Use 'path.package' instead.
See help("Deprecated")
gdata: read.xls support for 'XLS' (Excel 97-2004) files ENABLED.

gdata: read.xls support for 'XLSX' (Excel 2007+) files ENABLED.

Attaching package: ‘gdata’

The following object is masked from ‘package:randomForest’:

    combine

The following object is masked from ‘package:stats’:

    nobs

The following object is masked from ‘package:utils’:

    object.size

Loading required package: caTools
Loading required package: grid
Loading required package: KernSmooth
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
Loading required package: MASS

Attaching package: ‘gplots’

The following object is masked from ‘package:plotrix’:

    plotCI

The following object is masked from ‘package:stats’:

    lowess

Loading required package: rpart
Loading required package: abind

Attaching package: ‘DMwR’

The following object is masked from ‘package:plyr’:

    join

> set.seed(1237)
> smoted <- SMOTE(CARAVAN ~ ., data = trainingInd)
> 
> set.seed(1410)
> rfDown <- train(Class ~ ., data = downSampled,
+                 "rf",
+                 trControl = ctrl,
+                 ntree = 1500,
+                 tuneLength = 5,
+                 metric = "ROC")
> rfDown
822 samples
503 predictors
  2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 740, 740, 739, 739, 740, 740, ... 

Resampling results across tuning parameters:

  mtry  ROC    Sens   Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD
  2     0.693  0.638  0.645  0.641     0.283  0.0683  0.0931   0.117  
  7     0.68   0.618  0.657  0.638     0.275  0.068   0.0781   0.112  
  31    0.693  0.633  0.652  0.642     0.285  0.0627  0.0685   0.0792 
  126   0.697  0.635  0.659  0.647     0.295  0.0567  0.0653   0.073  
  502   0.682  0.628  0.637  0.633     0.265  0.0547  0.0619   0.0809 
  Accuracy SD  Kappa SD
  0.0619       0.124   
  0.0641       0.128   
  0.0556       0.111   
  0.0464       0.0928  
  0.0403       0.0807  

ROC was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 126. 
> 
> evalResults$RFdown <- predict(rfDown, evaluationInd, type = "prob")[,1]
> testResults$RFdown <- predict(rfDown, testingInd, type = "prob")[,1]
> rfDownROC <- roc(evalResults$CARAVAN, evalResults$RFdown,
+                  levels = rev(levels(evalResults$CARAVAN)))
> rfDownROC

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$RFdown,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$RFdown in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7937
> 
> set.seed(1401)
> rfDownInt <- train(CARAVAN ~ ., data = trainingInd,
+                    "rf",
+                    ntree = 1500,
+                    tuneLength = 5,
+                    strata = training$CARAVAN,
+                    sampsize = rep(sum(training$CARAVAN == "insurance"), 2),
+                    metric = "ROC",
+                    trControl = ctrl)
> rfDownInt
6877 samples
 503 predictors
   2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 6189, 6190, 6190, 6189, 6189, 6189, ... 

Resampling results across tuning parameters:

  mtry  ROC    Sens   Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD
  2     0.7    0.151  0.969  0.92      0.145  0.0311  0.0363   0.00479
  7     0.706  0.426  0.836  0.812     0.135  0.0317  0.077    0.0192 
  31    0.719  0.411  0.86   0.833     0.155  0.0266  0.0588   0.0189 
  126   0.722  0.436  0.845  0.82      0.149  0.032   0.0671   0.0176 
  502   0.718  0.467  0.824  0.803     0.144  0.036   0.0623   0.0195 
  Accuracy SD  Kappa SD
  0.00577      0.0454  
  0.0172       0.0367  
  0.0175       0.0352  
  0.0167       0.037   
  0.0191       0.0359  

ROC was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 126. 
> 
> evalResults$RFdownInt <- predict(rfDownInt, evaluationInd, type = "prob")[,1]
> testResults$RFdownInt <- predict(rfDownInt, testingInd, type = "prob")[,1]
> rfDownIntRoc <- roc(evalResults$CARAVAN,
+                     evalResults$RFdownInt,
+                     levels = rev(levels(training$CARAVAN)))
> rfDownIntRoc

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$RFdownInt,     levels = rev(levels(training$CARAVAN)))

Data: evalResults$RFdownInt in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7915
> 
> set.seed(1410)
> rfUp <- train(Class ~ ., data = upSampled,
+               "rf",
+               trControl = ctrl,
+               ntree = 1500,
+               tuneLength = 5,
+               metric = "ROC")
> rfUp
12932 samples
  503 predictors
    2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 11640, 11638, 11639, 11638, 11638, 11640, ... 

Resampling results across tuning parameters:

  mtry  ROC    Sens   Spec   Accuracy  Kappa  ROC SD   Sens SD  Spec SD
  2     0.864  0.836  0.727  0.782     0.563  0.011    0.0123   0.0183 
  7     0.987  0.993  0.86   0.926     0.853  0.00383  0.00384  0.0245 
  31    0.993  0.999  0.938  0.969     0.937  0.00309  0.00167  0.0131 
  126   0.993  1      0.951  0.976     0.951  0.00287  0        0.0107 
  502   0.992  1      0.943  0.971     0.943  0.00381  0        0.0123 
  Accuracy SD  Kappa SD
  0.00817      0.0163  
  0.0113       0.0226  
  0.00689      0.0138  
  0.00534      0.0107  
  0.00615      0.0123  

ROC was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 126. 
> 
> evalResults$RFup <- predict(rfUp, evaluationInd, type = "prob")[,1]
> testResults$RFup <- predict(rfUp, testingInd, type = "prob")[,1]
> rfUpROC <- roc(evalResults$CARAVAN, evalResults$RFup,
+                levels = rev(levels(evalResults$CARAVAN)))
> rfUpROC

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$RFup,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$RFup in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7522
> 
> set.seed(1410)
> rfSmote <- train(CARAVAN ~ ., data = smoted,
+                  "rf",
+                  trControl = ctrl,
+                  ntree = 1500,
+                  tuneLength = 5,
+                  metric = "ROC")
> rfSmote
2877 samples
 503 predictors
   2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 2590, 2589, 2589, 2590, 2588, 2590, ... 

Resampling results across tuning parameters:

  mtry  ROC    Sens   Spec   Accuracy  Kappa  ROC SD  Sens SD  Spec SD
  2     0.905  0.665  0.998  0.855     0.692  0.022   0.0304   0.00409
  7     0.908  0.694  0.973  0.853     0.69   0.0173  0.027    0.0218 
  31    0.914  0.731  0.948  0.855     0.697  0.0163  0.0262   0.0231 
  126   0.919  0.734  0.94   0.852     0.69   0.0142  0.0239   0.0208 
  502   0.912  0.741  0.927  0.847     0.682  0.0154  0.022    0.0288 
  Accuracy SD  Kappa SD
  0.0134       0.0297  
  0.0198       0.0416  
  0.019        0.0395  
  0.0167       0.0347  
  0.0218       0.0445  

ROC was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 126. 
> 
> evalResults$RFsmote <- predict(rfSmote, evaluationInd, type = "prob")[,1]
> testResults$RFsmote <- predict(rfSmote, testingInd, type = "prob")[,1]
> rfSmoteROC <- roc(evalResults$CARAVAN, evalResults$RFsmote,
+                   levels = rev(levels(evalResults$CARAVAN)))
> rfSmoteROC

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$RFsmote,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$RFsmote in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.7663
> 
> rfSmoteCM <- confusionMatrix(predict(rfSmote, evaluationInd), evalResults$CARAVAN)
> rfSmoteCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          11          53
  noinsurance        48         871
                                          
               Accuracy : 0.8973          
                 95% CI : (0.8766, 0.9155)
    No Information Rate : 0.94            
    P-Value [Acc > NIR] : 1.0000          
                                          
                  Kappa : 0.1242          
 Mcnemar's Test P-Value : 0.6906          
                                          
            Sensitivity : 0.18644         
            Specificity : 0.94264         
         Pos Pred Value : 0.17187         
         Neg Pred Value : 0.94777         
             Prevalence : 0.06002         
         Detection Rate : 0.01119         
   Detection Prevalence : 0.06511         
                                          
       'Positive' Class : insurance       
                                          
> 
> samplingSummary <- function(x, evl, tst)
+   {
+     lvl <- rev(levels(tst$CARAVAN))
+     evlROC <- roc(evl$CARAVAN,
+                   predict(x, evl, type = "prob")[,1],
+                   levels = lvl)
+     rocs <- c(auc(evlROC),
+               auc(roc(tst$CARAVAN,
+                       predict(x, tst, type = "prob")[,1],
+                       levels = lvl)))
+     cut <- coords(evlROC, x = "best", ret="threshold",
+                   best.method="closest.topleft")
+     bestVals <- coords(evlROC, cut, ret=c("sensitivity", "specificity"))
+     out <- c(rocs, bestVals*100)
+     names(out) <- c("evROC", "tsROC", "tsSens", "tsSpec")
+     out
+ 
+   }
> 
> rfResults <- rbind(samplingSummary(rfFit, evaluationInd, testingInd),
+                    samplingSummary(rfDown, evaluationInd, testingInd),
+                    samplingSummary(rfDownInt, evaluationInd, testingInd),
+                    samplingSummary(rfUp, evaluationInd, testingInd),
+                    samplingSummary(rfSmote, evaluationInd, testingInd))
> rownames(rfResults) <- c("Original", "Down--Sampling",  "Down--Sampling (Internal)",
+                          "Up--Sampling", "SMOTE")
> 
> rfResults
                              evROC     tsROC   tsSens   tsSpec
Original                  0.7569337 0.7377811 64.40678 75.86580
Down--Sampling            0.7936936 0.7302719 81.35593 70.34632
Down--Sampling (Internal) 0.7915474 0.7643227 77.96610 68.29004
Up--Sampling              0.7522379 0.7348391 72.88136 65.58442
SMOTE                     0.7663255 0.7360509 79.66102 65.47619
> 
> rocCols <- c("black", rgb(1, 0, 0, .5), rgb(0, 0, 1, .5))
> 
> plot(roc(testResults$CARAVAN, testResults$RF, levels = rev(levels(testResults$CARAVAN))),
+      type = "S", col = rocCols[1], legacy.axes = TRUE)

Call:
roc.default(response = testResults$CARAVAN, predictor = testResults$RF,     levels = rev(levels(testResults$CARAVAN)))

Data: testResults$RF in 1846 controls (testResults$CARAVAN noinsurance) < 116 cases (testResults$CARAVAN insurance).
Area under the curve: 0.7378
> plot(roc(testResults$CARAVAN, testResults$RFdownInt, levels = rev(levels(testResults$CARAVAN))),
+      type = "S", col = rocCols[2],add = TRUE, legacy.axes = TRUE)

Call:
roc.default(response = testResults$CARAVAN, predictor = testResults$RFdownInt,     levels = rev(levels(testResults$CARAVAN)))

Data: testResults$RFdownInt in 1846 controls (testResults$CARAVAN noinsurance) < 116 cases (testResults$CARAVAN insurance).
Area under the curve: 0.7643
> plot(roc(testResults$CARAVAN, testResults$RFsmote, levels = rev(levels(testResults$CARAVAN))),
+      type = "S", col = rocCols[3], add = TRUE, legacy.axes = TRUE)

Call:
roc.default(response = testResults$CARAVAN, predictor = testResults$RFsmote,     levels = rev(levels(testResults$CARAVAN)))

Data: testResults$RFsmote in 1846 controls (testResults$CARAVAN noinsurance) < 116 cases (testResults$CARAVAN insurance).
Area under the curve: 0.7361
> legend(.6, .4,
+        c("Normal", "Down-Sampling (Internal)", "SMOTE"),
+        lty = rep(1, 3),
+        lwd = rep(2, 3),
+        cex = .8,
+        col = rocCols)
> 
> xyplot(lift(CARAVAN ~ RF + RFdownInt + RFsmote,
+             data = testResults),
+        type = "l",
+        ylab = "%Events Found",
+        xlab =  "%Customers Evaluated")
> 
> 
> ################################################################################
> ### Section 16.8 Cost–Sensitive Training
> 
> library(kernlab)
> 
> set.seed(1157)
> sigma <- sigest(CARAVAN ~ ., data = trainingInd[, noNZVSet], frac = .75)
> names(sigma) <- NULL
> 
> svmGrid1 <- data.frame(.sigma = sigma[2],
+                        .C = 2^c(2:10))
> 
> set.seed(1401)
> svmFit <- train(CARAVAN ~ .,
+                 data = trainingInd[, noNZVSet],
+                 method = "svmRadial",
+                 tuneGrid = svmGrid1,
+                 preProc = c("center", "scale"),
+                 metric = "Kappa",
+                 trControl = ctrl)
> svmFit
6877 samples
 203 predictors
   2 classes: 'insurance', 'noinsurance' 

Pre-processing: centered, scaled 
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 6189, 6190, 6190, 6189, 6189, 6189, ... 

Resampling results across tuning parameters:

  C     ROC    Sens     Spec   Accuracy  Kappa      ROC SD  Sens SD  Spec SD
  4     0.665  0        0.999  0.939     -0.00225   0.0465  0        0.00122
  8     0.671  0        0.996  0.936     -0.00734   0.0476  0        0.00207
  16    0.678  0.00732  0.993  0.934     -0.000274  0.041   0.0118   0.00159
  32    0.678  0.0413   0.982  0.926     0.0341     0.0368  0.02     0.00388
  64    0.668  0.0901   0.968  0.916     0.0706     0.0399  0.0461   0.00846
  128   0.655  0.105    0.958  0.907     0.0712     0.039   0.0366   0.00951
  256   0.648  0.114    0.953  0.903     0.0745     0.0395  0.0367   0.0104 
  512   0.644  0.112    0.953  0.902     0.07       0.0401  0.0369   0.0111 
  1020  0.643  0.117    0.952  0.902     0.0738     0.037   0.0429   0.01   
  Accuracy SD  Kappa SD
  0.00125      0.00221 
  0.00212      0.00346 
  0.00182      0.0202  
  0.00358      0.0263  
  0.00765      0.0486  
  0.00961      0.0446  
  0.0109       0.0472  
  0.011        0.0437  
  0.0101       0.0475  

Tuning parameter 'sigma' was held constant at a value of 0.00245
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were C = 256 and sigma = 0.00245. 
> 
> evalResults$SVM <- predict(svmFit, evaluationInd[, noNZVSet], type = "prob")[,1]
> testResults$SVM <- predict(svmFit, testingInd[, noNZVSet], type = "prob")[,1]
> svmROC <- roc(evalResults$CARAVAN, evalResults$SVM,
+               levels = rev(levels(evalResults$CARAVAN)))
> svmROC

Call:
roc.default(response = evalResults$CARAVAN, predictor = evalResults$SVM,     levels = rev(levels(evalResults$CARAVAN)))

Data: evalResults$SVM in 924 controls (evalResults$CARAVAN noinsurance) < 59 cases (evalResults$CARAVAN insurance).
Area under the curve: 0.6923
> 
> svmTestROC <- roc(testResults$CARAVAN, testResults$SVM,
+                   levels = rev(levels(testResults$CARAVAN)))
> svmTestROC

Call:
roc.default(response = testResults$CARAVAN, predictor = testResults$SVM,     levels = rev(levels(testResults$CARAVAN)))

Data: testResults$SVM in 1846 controls (testResults$CARAVAN noinsurance) < 116 cases (testResults$CARAVAN insurance).
Area under the curve: 0.6704
> 
> confusionMatrix(predict(svmFit, evaluationInd[, noNZVSet]), evalResults$CARAVAN)
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance           5          45
  noinsurance        54         879
                                          
               Accuracy : 0.8993          
                 95% CI : (0.8788, 0.9174)
    No Information Rate : 0.94            
    P-Value [Acc > NIR] : 1.0000          
                                          
                  Kappa : 0.0388          
 Mcnemar's Test P-Value : 0.4214          
                                          
            Sensitivity : 0.084746        
            Specificity : 0.951299        
         Pos Pred Value : 0.100000        
         Neg Pred Value : 0.942122        
             Prevalence : 0.060020        
         Detection Rate : 0.005086        
   Detection Prevalence : 0.050865        
                                          
       'Positive' Class : insurance       
                                          
> 
> confusionMatrix(predict(svmFit, testingInd[, noNZVSet]), testingInd$CARAVAN)
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          18          80
  noinsurance        98        1766
                                          
               Accuracy : 0.9093          
                 95% CI : (0.8957, 0.9216)
    No Information Rate : 0.9409          
    P-Value [Acc > NIR] : 1.0000          
                                          
                  Kappa : 0.1206          
 Mcnemar's Test P-Value : 0.2026          
                                          
            Sensitivity : 0.155172        
            Specificity : 0.956663        
         Pos Pred Value : 0.183673        
         Neg Pred Value : 0.947425        
             Prevalence : 0.059123        
         Detection Rate : 0.009174        
   Detection Prevalence : 0.049949        
                                          
       'Positive' Class : insurance       
                                          
> 
> svmGrid2 <- data.frame(.sigma = sigma[2],
+                       .C = 2^seq(-6, 1, length = 15))
> set.seed(1401)
> svmWtFit <- train(CARAVAN ~ .,
+                   data = trainingInd[, noNZVSet],
+                   method = "svmRadial",
+                   tuneGrid = svmGrid2,
+                   preProc = c("center", "scale"),
+                   metric = "Kappa",
+                   class.weights = c(insurance = 18, noinsurance = 1),
+                   trControl = ctrlNoProb)
> svmWtFit
6877 samples
 203 predictors
   2 classes: 'insurance', 'noinsurance' 

Pre-processing: centered, scaled 
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 6189, 6190, 6190, 6189, 6189, 6189, ... 

Resampling results across tuning parameters:

  C       Accuracy  Kappa   Sens   Spec   Accuracy SD  Kappa SD  Sens SD
  0.0156  0.557     0.0682  0.742  0.545  0.0213       0.0141    0.0537 
  0.0221  0.614     0.0806  0.691  0.609  0.0232       0.0146    0.0547 
  0.0312  0.637     0.0864  0.669  0.635  0.0221       0.0187    0.0648 
  0.0442  0.644     0.0883  0.662  0.643  0.0228       0.0222    0.071  
  0.0625  0.658     0.0939  0.657  0.658  0.0219       0.0201    0.0644 
  0.0884  0.672     0.0958  0.633  0.674  0.0232       0.0202    0.0478 
  0.125   0.684     0.101   0.625  0.688  0.0217       0.0202    0.0535 
  0.177   0.7       0.106   0.611  0.705  0.0186       0.0138    0.041  
  0.25    0.711     0.108   0.591  0.719  0.0206       0.0164    0.0352 
  0.354   0.724     0.111   0.572  0.734  0.0193       0.0166    0.0433 
  0.5     0.737     0.112   0.543  0.75   0.0198       0.0178    0.0427 
  0.707   0.75      0.109   0.506  0.765  0.0191       0.0274    0.0661 
  1       0.765     0.104   0.46   0.785  0.0161       0.0259    0.0759 
  1.41    0.776     0.097   0.416  0.799  0.0162       0.0281    0.0799 
  2       0.791     0.102   0.394  0.817  0.0186       0.0356    0.0803 
  Spec SD
  0.0226 
  0.0256 
  0.0241 
  0.0242 
  0.0237 
  0.0241 
  0.0231 
  0.0206 
  0.0221 
  0.0211 
  0.0216 
  0.0201 
  0.0188 
  0.0196 
  0.0206 

Tuning parameter 'sigma' was held constant at a value of 0.00245
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were C = 0.5 and sigma = 0.00245. 
> 
> svmWtEvalCM <- confusionMatrix(predict(svmWtFit, evaluationInd[, noNZVSet]), evalResults$CARAVAN)
> svmWtEvalCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          32         232
  noinsurance        27         692
                                          
               Accuracy : 0.7365          
                 95% CI : (0.7078, 0.7638)
    No Information Rate : 0.94            
    P-Value [Acc > NIR] : 1               
                                          
                  Kappa : 0.1109          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.54237         
            Specificity : 0.74892         
         Pos Pred Value : 0.12121         
         Neg Pred Value : 0.96245         
             Prevalence : 0.06002         
         Detection Rate : 0.03255         
   Detection Prevalence : 0.26857         
                                          
       'Positive' Class : insurance       
                                          
> 
> svmWtTestCM <- confusionMatrix(predict(svmWtFit, testingInd[, noNZVSet]), testingInd$CARAVAN)
> svmWtTestCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          66         442
  noinsurance        50        1404
                                          
               Accuracy : 0.7492          
                 95% CI : (0.7294, 0.7683)
    No Information Rate : 0.9409          
    P-Value [Acc > NIR] : 1               
                                          
                  Kappa : 0.1276          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.56897         
            Specificity : 0.76056         
         Pos Pred Value : 0.12992         
         Neg Pred Value : 0.96561         
             Prevalence : 0.05912         
         Detection Rate : 0.03364         
   Detection Prevalence : 0.25892         
                                          
       'Positive' Class : insurance       
                                          
> 
> 
> initialRpart <- rpart(CARAVAN ~ ., data = training,
+                       control = rpart.control(cp = 0.0001))
> rpartGrid <- data.frame(.cp = initialRpart$cptable[, "CP"])
> 
> cmat <- list(loss = matrix(c(0, 1, 20, 0), ncol = 2))
> set.seed(1401)
> cartWMod <- train(x = training[,predictors],
+                   y = training$CARAVAN,
+                   method = "rpart",
+                   trControl = ctrlNoProb,
+                   tuneGrid = rpartGrid,
+                   metric = "Kappa",
+                   parms = cmat)
> cartWMod
6877 samples
  85 predictors
   2 classes: 'insurance', 'noinsurance' 

No pre-processing
Resampling: Cross-Validation (10 fold) 

Summary of sample sizes: 6189, 6190, 6190, 6189, 6189, 6189, ... 

Resampling results across tuning parameters:

  cp        Accuracy  Kappa   Sens   Spec   Accuracy SD  Kappa SD  Sens SD
  1e-04     0.797     0.0734  0.316  0.828  0.018        0.0435    0.0918 
  0.000487  0.797     0.0744  0.319  0.827  0.0189       0.0423    0.0892 
  0.00122   0.778     0.0768  0.36   0.805  0.02         0.037     0.0883 
  0.00162   0.762     0.0844  0.411  0.785  0.0181       0.0298    0.0794 
  0.00243   0.722     0.0805  0.48   0.737  0.024        0.0253    0.0786 
  0.00278   0.707     0.0773  0.499  0.72   0.0229       0.0299    0.0916 
  Spec SD
  0.0203 
  0.0212 
  0.0229 
  0.0208 
  0.0274 
  0.0256 

Kappa was used to select the optimal model using  the largest value.
The final value used for the model was cp = 0.00162. 
> 
> 
> library(C50)
> c5Grid <- expand.grid(.model = c("tree", "rules"),
+                       .trials = c(1, (1:10)*10),
+                       .winnow = FALSE)
> 
> finalCost <- matrix(c(0, 20, 1, 0), ncol = 2)
> rownames(finalCost) <- colnames(finalCost) <- levels(training$CARAVAN)
> set.seed(1401)
> C5CostFit <- train(training[, predictors],
+                    training$CARAVAN,
+                    method = "C5.0",
+                    metric = "Kappa",
+                    tuneGrid = c5Grid,
+                    cost = finalCost,
+                    control = C5.0Control(earlyStopping = FALSE),
+                    trControl = ctrlNoProb)
> 
> C5CostCM <- confusionMatrix(predict(C5CostFit, testing), testing$CARAVAN)
> C5CostCM
Confusion Matrix and Statistics

             Reference
Prediction    insurance noinsurance
  insurance          64         623
  noinsurance        52        1223
                                         
               Accuracy : 0.656          
                 95% CI : (0.6345, 0.677)
    No Information Rate : 0.9409         
    P-Value [Acc > NIR] : 1              
                                         
                  Kappa : 0.0648         
 Mcnemar's Test P-Value : <2e-16         
                                         
            Sensitivity : 0.55172        
            Specificity : 0.66251        
         Pos Pred Value : 0.09316        
         Neg Pred Value : 0.95922        
             Prevalence : 0.05912        
         Detection Rate : 0.03262        
   Detection Prevalence : 0.35015        
                                         
       'Positive' Class : insurance      
                                         
> 
> 
> ################################################################################
> ### Session Information
> 
> sessionInfo()
R version 3.0.0 RC (2013-03-27 r62426)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] grid      parallel  stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
 [1] C50_0.1.0-14       kernlab_0.9-16     DMwR_0.3.0         abind_1.4-0       
 [5] rpart_4.1-1        ROCR_1.0-4         gplots_2.11.0      MASS_7.3-26       
 [9] KernSmooth_2.23-10 caTools_1.14       gdata_2.12.0       gtools_2.7.0      
[13] quantmod_0.4-0     TTR_0.21-1         Defaults_1.1-1     xts_0.9-3         
[17] zoo_1.7-9          earth_3.2-3        plotrix_3.4-6      plotmo_1.3-2      
[21] leaps_2.9          mda_0.4-2          e1071_1.6-1        class_7.3-7       
[25] pROC_1.5.4         randomForest_4.6-7 doMC_1.3.0         iterators_1.0.6   
[29] caret_5.15-61      reshape2_1.2.2     plyr_1.8           foreach_1.4.0     
[33] cluster_1.14.4     DWD_0.10           Matrix_1.0-12      lattice_0.20-15   

loaded via a namespace (and not attached):
[1] bitops_1.0-5    codetools_0.2-8 compiler_3.0.0  stringr_0.6.2  
[5] tools_3.0.0    
> 
> q("no")
> proc.time()
      user     system    elapsed 
358315.343   5239.689  72001.525 
